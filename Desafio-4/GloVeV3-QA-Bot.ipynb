{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Bot QA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: right;\">\n",
    "\t<h1 style=\"display: inline-block;margin: 0;padding: 8px 16px;color: white;background: linear-gradient(to right,rgb(17, 75, 141), #4CAF50);border-radius: 12px;font-size: 1.8rem;box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);\"> teoría </h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "Modelo PLN arquitectura seq2seq  (sequence-to-sequence) con:\n",
    "- Encoder: Procesa la oración en inglés\n",
    "- Decoder: Genera la traducción en españo\n",
    "\n",
    "\n",
    "\n",
    " Frameworks para crear modelos seq2seq\n",
    " 20\n",
    " Algunos frameworks/librerías que traen modelos e interfaces \n",
    "preparadas para armar rápidamente un sistema basado en NLP\n",
    "\n",
    "Hola.\n",
    "\n",
    "**Seq2Seq** (sequence-to-sequence), que es el nombre de la arquitectura, y las partes que la componen, Encoder LSTM y Decoder LSTM.\n",
    "\n",
    "- Seq2Seq: Es el nombre del tipo de arquitectura o esquema general que se usa para transformar una secuencia en otra. Por ejemplo, traducir una oración de inglés a español, resumir un texto largo, o generar una respuesta en un chat.\n",
    "\n",
    "- Encoder LSTM: Es el componente de la arquitectura Seq2Seq que se encarga de procesar la secuencia de entrada. En este caso, el componente es una red neuronal de tipo LSTM (Long Short-Term Memory), que es un tipo especializado de RNN (Recurrent Neural Network) muy bueno para capturar las dependencias en secuencias de datos. El encoder \"lee\" la oración palabra por palabra y la comprime en un vector de contexto.\n",
    "\n",
    "- Decoder LSTM: Es el otro componente de la arquitectura Seq2Seq que se encarga de generar la secuencia de salida, también usando una red LSTM. El decoder toma el vector de contexto del encoder y, basándose en este y en las palabras que ya ha generado, predice la siguiente palabra de la secuencia de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las librerías ya están instaladas\n"
     ]
    }
   ],
   "source": [
    "# descarga del dataset desde kagglehub\n",
    "# Instalamos librerias\n",
    "try:\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.text import one_hot \n",
    "    from tqdm import tqdm\n",
    "    #import gdown\n",
    "    print(\"Todas las librerías ya están instaladas\")\n",
    "except ImportError:\n",
    "    !pip install tqdm\n",
    "    #!pip install --upgrade --no-cache-dir gdown\n",
    "    !pip install keras tensorflow\n",
    "    print(\"Instalación completada\")\n",
    "    from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### 1 - Datos\n",
    "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT  de preguntas y respuestas (Question and answers Bot QA-bot) para responder a preguntas del usuario (QA). [LINK](http://convai.io/data/) utilizaremos al arquitectura de modelo **Seq2Seq** (sequence-to-sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bDFC0I3j9oFD"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade --no-cache-dir gdown --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import re  # Faltaba esta importación\n",
    "\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.preprocessing.text import Tokenizer librerias viejas \n",
    "#from keras.preprocessing.text import one_hot librerias viejas \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import one_hot  \n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga y preparación del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RHNkUaPp6aYq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset ya se encuentra descargado\n"
     ]
    }
   ],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "import os\n",
    "import gdown\n",
    "if os.access('data_volunteers.json', os.F_OK) is False:\n",
    "    #url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
    "    url = 'http://convai.io/data/data_volunteers.json'\n",
    "    output = 'data_volunteers.json'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WZy1-wgG-Rp7"
   },
   "outputs": [],
   "source": [
    "# dataset_file\n",
    "import json\n",
    "\n",
    "text_file = \"data_volunteers.json\"\n",
    "with open(text_file) as f:\n",
    "    data = json.load(f) # la variable data será un diccionario\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">\n",
    "\t<h1 style=\"display: inline-block;margin: 0;padding: 8px 16px;color: white;background: linear-gradient(to right,rgb(17, 75, 141), #4CAF50);border-radius: 12px;font-size: 1.8rem;box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);\">⚠️ desarrollar </h1>\n",
    "</div>\n",
    "\n",
    "# Ejecutar con modelos \n",
    "- GloVe 50d \n",
    "- FastText 50d \n",
    "\n",
    "### 2 - Preprocesamiento\n",
    "Realizar el preprocesamiento necesario para obtener:\n",
    "- word2idx_inputs, max_input_len\n",
    "- word2idx_outputs, max_out_len, num_words_output\n",
    "- encoder_input_sequences, decoder_output_sequences, decoder_targets\n",
    "\n",
    "### 3 - Preparar los embeddings\n",
    "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores\n",
    "\n",
    "### 4 - Entrenar el modelo\n",
    "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase.\n",
    "\n",
    "### 5 - Inferencia\n",
    "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ue5qd54S-eew"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar los campos disponibles en cada linea del dataset\n",
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos: <class 'list'>\n",
      "Cantidad de elementos: 1111\n",
      "\n",
      "Primeros 2 elementos:\n",
      "[{'bot_profile': ['i like to talk but people have a hard time understanding.',\n",
      "                  'i like to look at blocks and sing about letters.',\n",
      "                  'i like to eat chocolate candy.',\n",
      "                  'when i grow up i want to be a dog.'],\n",
      "  'dialog': [{'evaluation_score': None,\n",
      "              'id': 0,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'hi there'}],\n",
      "  'end_time': '2018-10-29 03:32:08.296000',\n",
      "  'eval_score': None,\n",
      "  'participant1_id': {'class': 'User', 'user_id': 'User 00172'},\n",
      "  'participant2_id': {'class': 'Bot', 'user_id': 'Bot 004'},\n",
      "  'profile_match': '',\n",
      "  'start_time': '2018-10-29 03:32:08.296000',\n",
      "  'user_profile': ['i am a clean eater.',\n",
      "                   'my parents were both very athletic.',\n",
      "                   'i love running and preparing for marathons.',\n",
      "                   'i am a cancer survivor.']},\n",
      " {'bot_profile': ['my favorite singer is taylor swift.',\n",
      "                  'i love eating out with friends.',\n",
      "                  \"i'm getting married in the spring.\",\n",
      "                  'i work at a school as a kindergarten teacher.',\n",
      "                  \"i'm 24 years old.\"],\n",
      "  'dialog': [{'evaluation_score': None,\n",
      "              'id': 0,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'Hello!'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 1,\n",
      "              'sender': 'participant2',\n",
      "              'sender_class': 'Bot',\n",
      "              'text': 'Hi! How are you?'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 2,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'Not bad! And You?'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 3,\n",
      "              'sender': 'participant2',\n",
      "              'sender_class': 'Bot',\n",
      "              'text': \"I'm doing well. Just got engaged to my high school \"\n",
      "                      'sweetheart.'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 4,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'Wowowowow! Congratulations! Is she pretty?'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 5,\n",
      "              'sender': 'participant2',\n",
      "              'sender_class': 'Bot',\n",
      "              'text': \"She 's pretty cute. She invited me to dinner tonight. \"\n",
      "                      '🙂'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 6,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'Cool! Have a good time you both! And what is your '\n",
      "                      'hobby?'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 7,\n",
      "              'sender': 'participant2',\n",
      "              'sender_class': 'Bot',\n",
      "              'text': 'I love music! I love Taylor swift. 😉'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 8,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'Me too. And what about Iggy Pop?'},\n",
      "             {'evaluation_score': 1,\n",
      "              'id': 9,\n",
      "              'sender': 'participant2',\n",
      "              'sender_class': 'Bot',\n",
      "              'text': 'I love Ziggy! He is my favorite. Are you and your wife '\n",
      "                      'millennial too?'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 10,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': \"I have no wife. And I'm not millenial, I'm X \"\n",
      "                      'generation.'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 11,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'Hey? Where are you?'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 12,\n",
      "              'sender': 'participant2',\n",
      "              'sender_class': 'Bot',\n",
      "              'text': 'I am sorry to hear that. What do you do for fun?'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 13,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': \"I'm playing pipe organ.\"},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 14,\n",
      "              'sender': 'participant2',\n",
      "              'sender_class': 'Bot',\n",
      "              'text': 'That sounds impressive. I like to go out to eat with my '\n",
      "                      'friends.'},\n",
      "             {'evaluation_score': None,\n",
      "              'id': 15,\n",
      "              'sender': 'participant1',\n",
      "              'sender_class': 'Human',\n",
      "              'text': 'Cool! See ya!'}],\n",
      "  'end_time': '2018-10-29 09:12:32',\n",
      "  'eval_score': 5,\n",
      "  'participant1_id': {'class': 'User', 'user_id': 'User 00892'},\n",
      "  'participant2_id': {'class': 'Bot', 'user_id': 'Bot 002'},\n",
      "  'profile_match': 1,\n",
      "  'start_time': '2018-10-29 09:08:40',\n",
      "  'user_profile': ['they are constantly on my back.',\n",
      "                   'i do not drink or do drugs or anything.',\n",
      "                   'i am 19 and i cannot wait to move out 19 my parents home.',\n",
      "                   'i work took i have a part time job at burger king.']}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Ver las primeras líneas del JSON original\n",
    "print(\"Tipo de datos:\", type(data))\n",
    "print(\"Cantidad de elementos:\", len(data))\n",
    "print(\"\\nPrimeros 2 elementos:\")\n",
    "\n",
    "pprint.pprint(data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructura del datset:\n",
      "Keys disponibles: dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])\n",
      "\n",
      "Primer diálogo completo:\n",
      "{'bot_profile': ['i like to talk but people have a hard time understanding.',\n",
      "                 'i like to look at blocks and sing about letters.',\n",
      "                 'i like to eat chocolate candy.',\n",
      "                 'when i grow up i want to be a dog.'],\n",
      " 'dialog': [{'evaluation_score': None,\n",
      "             'id': 0,\n",
      "             'sender': 'participant1',\n",
      "             'sender_class': 'Human',\n",
      "             'text': 'hi there'}],\n",
      " 'end_time': '2018-10-29 03:32:08.296000',\n",
      " 'eval_score': None,\n",
      " 'participant1_id': {'class': 'User', 'user_id': 'User 00172'},\n",
      " 'participant2_id': {'class': 'Bot', 'user_id': 'Bot 004'},\n",
      " 'profile_match': '',\n",
      " 'start_time': '2018-10-29 03:32:08.296000',\n",
      " 'user_profile': ['i am a clean eater.',\n",
      "                  'my parents were both very athletic.',\n",
      "                  'i love running and preparing for marathons.',\n",
      "                  'i am a cancer survivor.']}\n"
     ]
    }
   ],
   "source": [
    "# Ver la estructura de un diálogo completo\n",
    "print(\"Estructura del datset:\")\n",
    "print(\"Keys disponibles:\", data[0].keys())\n",
    "print(\"\\nPrimer diálogo completo:\")\n",
    "pprint.pprint(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Preprocesamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la limpieza de los datos para que pueda ser utilizado en el modelo de red neuronal de tipo  Sequence to Sequence **Seq2Seq**. \n",
    "\n",
    "Tomamos las conversaciones crudas del archivo JSON, dividirlas en pares de \"pregunta-respuesta\", limpiar el texto y formatearlo de una manera muy específica que los modelos como LSTM necesitan para aprender a conversar.\n",
    "\n",
    "#### Algunas configuraciones relavantes para el QA-bot (Question and Answer bot)\n",
    "\n",
    "- max_len = 30: Define la longitud máxima (en caracteres) que una oración puede tener. Si la pregunta o la respuesta superan este límite, se descartan. Esto se hace para mantener la uniformidad y evitar que el modelo procese textos excesivamente largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jHBRAXPl-3dz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows utilizadas: 6033\n"
     ]
    }
   ],
   "source": [
    "# Preparación del DataSet. \n",
    "chat_in = [] # Variable temporal donde se guardará cada frase de entrada (pregunta).\n",
    "chat_out = [] # Variable temporal donde se guardará cada frase de salida (respuesta).\n",
    "\n",
    "input_sentences = []  # se guardarán todas las \"preguntas\" (las frases de entrada para el modelo).\n",
    "output_sentences = [] # se guardarán las \"respuestas\" que el modelo debe aprender a generar, , terminadas con <eos>.\n",
    "# modificada de las respuestas que se usa para \"enseñarle\" al modelo durante el entrenamiento (un concepto llamado teacher forcing)\n",
    "output_sentences_inputs = [] # Respuestas de entrada al decodificador, empezadas con <sos>.\n",
    "max_len = 30 # Define la longitud máxima (en caracteres) que una oración puede tener.\n",
    "\n",
    "\n",
    "# Función para limpiar el texto (preprocesamiento básico)\n",
    "def clean_text(txt): \n",
    "    txt = txt.lower()               # Convierte todo el texto a minúsculas\n",
    "    txt.replace(\"\\'d\", \" had\")      # I'd -> I had\n",
    "    txt.replace(\"\\'s\", \" is\")       # She's -> She is\n",
    "    txt.replace(\"\\'m\", \" am\")       # I'm -> I am\n",
    "    txt.replace(\"don't\", \"do not\")  # don't -> do not\n",
    "    # Eliminación de caracteres que no sean letras, números o guiones bajos\n",
    "    # Reemplaza por un espacio cualquier cosa que no sea alfanumérica\n",
    "    txt = re.sub(r'\\W+', ' ', txt) \n",
    "    # ejemplo \n",
    "    #        re.sub(r'\\W+', ' ', \"Hello!!! How's it going?\")  \n",
    "    #                             → \"Hello How s it going \"\n",
    "\n",
    "\n",
    "    \n",
    "    return txt\n",
    "# Iteramos por cada \"línea\" (registro) en el dataset JSON\n",
    "for line in data:\n",
    "    for i in range(len(line['dialog'])-1):\n",
    "        # vamos separando el texto en \"preguntas\" (chat_in)\n",
    "        # Cada registro contiene un diálogo (lista de frases).\n",
    "        # y \"respuestas\" (chat_out)\n",
    "        # Vamos a emparejar cada oración con la siguiente (pregunta-respuesta).\n",
    "        chat_in = clean_text(line['dialog'][i]['text']) # Extraemos y limpiamos el texto de la pregunta\n",
    "        chat_out = clean_text(line['dialog'][i+1]['text']) # Extraemos y limpiamos el texto de la respuesta\n",
    "\n",
    "        # Si la pregunta o respuesta excede la longitud máxima, la descartamos\n",
    "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
    "            continue\n",
    "\n",
    "        input_sentence, output = chat_in, chat_out\n",
    "        \n",
    "        # output sentence (decoder_output) tiene <eos>\n",
    "        # La salida del decodificador (respuesta esperada) termina con <eos>\n",
    "        output_sentence = output + ' <eos>'\n",
    "        # output sentence input (decoder_input) tiene <sos>\n",
    "        # La entrada del decodificador (teacher forcing) empieza con <sos>\n",
    "        output_sentence_input = '<sos> ' + output\n",
    "\n",
    "        # Añadimos a las listas finales\n",
    "        input_sentences.append(input_sentence)      # Pregunta limpia\n",
    "        output_sentences.append(output_sentence)    # Respuesta con <eos>\n",
    "        output_sentences_inputs.append(output_sentence_input)   # Respuesta con <sos>\n",
    "\n",
    "# Mostramos cuántas parejas de frases válidas quedaron - pares de pregunta-respuesta procesados\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "07L1qj8pC_l6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EJEMPLOS DE CONVERSACIONES ===\n",
      "\n",
      "Ejemplo 1:\n",
      "INPUT:  hello \n",
      "OUTPUT: hi how are you  <eos>\n",
      "OUTPUT_INPUT: <sos> hi how are you \n",
      "\n",
      "Ejemplo 2:\n",
      "INPUT:  hi how are you \n",
      "OUTPUT: not bad and you  <eos>\n",
      "OUTPUT_INPUT: <sos> not bad and you \n",
      "\n",
      "Ejemplo 3:\n",
      "INPUT:  hi \n",
      "OUTPUT: hello  <eos>\n",
      "OUTPUT_INPUT: <sos> hello \n",
      "\n",
      "Ejemplo 4:\n",
      "INPUT:  hi \n",
      "OUTPUT: hello  <eos>\n",
      "OUTPUT_INPUT: <sos> hello \n",
      "\n",
      "Ejemplo 5:\n",
      "INPUT:  hi \n",
      "OUTPUT: hello how are you today  <eos>\n",
      "OUTPUT_INPUT: <sos> hello how are you today \n"
     ]
    }
   ],
   "source": [
    "# Ver ejemplos de conversaciones procesadas\n",
    "print(\"=== EJEMPLOS DE CONVERSACIONES ===\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nEjemplo {i+1}:\")\n",
    "    print(f\"INPUT:  {input_sentences[i]}\")\n",
    "    print(f\"OUTPUT: {output_sentences[i]}\")\n",
    "    print(f\"OUTPUT_INPUT: {output_sentences_inputs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTADÍSTICAS ===\n",
      "         input_len   output_len\n",
      "count  6033.000000  6033.000000\n",
      "mean      3.777557     5.050390\n",
      "std       2.126842     2.074806\n",
      "min       0.000000     1.000000\n",
      "25%       2.000000     3.000000\n",
      "50%       4.000000     5.000000\n",
      "75%       5.000000     7.000000\n",
      "max       9.000000    10.000000\n"
     ]
    }
   ],
   "source": [
    "# Análisis de longitudes\n",
    "#import pandas as pd\n",
    "\n",
    "df_analysis = pd.DataFrame({\n",
    "    'input_len': [len(s.split()) for s in input_sentences],\n",
    "    'output_len': [len(s.split()) for s in output_sentences]\n",
    "})\n",
    "\n",
    "print(\"=== ESTADÍSTICAS ===\")\n",
    "print(df_analysis.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración:\n",
      "- MAX_VOCAB_SIZE: 8000\n",
      "- max_input_len: 10\n",
      "- max_out_len: 12\n",
      "- Dataset disponible: 6033 pares pregunta y respuesta \n",
      "\n",
      "info  del vocabulario:\n",
      "- Palabras únicas en preguntas: 1799\n",
      "- Palabras únicas en respuestas: 1806\n",
      "- Vocabulario final inputs: 1800\n",
      "- Vocabulario final outputs: 1807\n",
      "- Longitud máxima real inputs: 9\n",
      "- Longitud máxima real outputs: 10\n",
      " Tokens especiales <sos> y <eos> encontrados\n",
      "- Índice <sos>: 1\n",
      "- Índice <eos>: 2\n",
      "\n",
      "Verificación de índices:\n",
      "- Índice máximo en secuencias: 1806\n",
      "- num_words_output: 1807\n",
      "- num_classes ajustado: 1807\n",
      " Shape de targets one-hot: (6033, 12, 1807)\n",
      "- Cada posición tiene 1807 clases posibles\n",
      "\n",
      "--- Verificación de diccionarios inversos ---\n",
      "idx2word_inputs creado: 1799 palabras\n",
      "idx2word_outputs creado: 1806 palabras\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# v3.PREPROCESAMIENTO - QA BOT\n",
    "# ============================================================================\n",
    "\n",
    "# Imports necesarios\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CONFIGURACIÓN DE HIPERPARÁMETROS\n",
    "# ==================================\n",
    "\n",
    "# Configuración del vocabulario y secuencias\n",
    "#MAX_VOCAB_SIZE = 4000 ->  error i an vegan\n",
    "MAX_VOCAB_SIZE = 8000      # Vocabulario máximo (conservador para RAM) 4000\n",
    "max_input_len = 10         # Longitud máxima de preguntas (palabras)\n",
    "max_out_len = 12          # Longitud máxima de respuestas (palabras)\n",
    "\n",
    "print(f\"Configuración:\")\n",
    "print(f\"- MAX_VOCAB_SIZE: {MAX_VOCAB_SIZE}\")\n",
    "print(f\"- max_input_len: {max_input_len}\")  \n",
    "print(f\"- max_out_len: {max_out_len}\")\n",
    "print(f\"- Dataset disponible: {len(input_sentences)} pares pregunta y respuesta \\n\")\n",
    "\n",
    "\n",
    "# CREAR TOKENIZERS \n",
    "# ==============================================================\n",
    "\n",
    "# Tokenizer para las PREGUNTAS (input)\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "# Tokenizer para las RESPUESTAS (output)\n",
    "# IMPORTANTE: Quitamos '<' y '>' de los filtros para conservar <sos> y <eos>\n",
    "output_tokenizer = Tokenizer(\n",
    "    num_words=MAX_VOCAB_SIZE, \n",
    "    filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n'\n",
    ")\n",
    "\n",
    "# Ajustar tokenizer con los tokens especiales y todas las respuestas\n",
    "all_output_sentences = [\"<sos>\", \"<eos>\"] + output_sentences + output_sentences_inputs\n",
    "output_tokenizer.fit_on_texts(all_output_sentences)\n",
    "\n",
    "# Convertir respuestas a secuencias numéricas\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "\n",
    "\n",
    "# GENERAR DICCIONARIOS PALABRA→ÍNDICE\n",
    "# =================================\n",
    "\n",
    "# Diccionarios para convertir palabras a índices\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "\n",
    "# Calcular longitudes máximas reales del dataset (ANTES del filtrado)\n",
    "max_input_len_real = max(len(sen) for sen in input_integer_seq)\n",
    "max_out_len_real = max(len(sen) for sen in output_integer_seq)\n",
    "\n",
    "# Información del vocabulario\n",
    "# IMPORTANTE: +1 para incluir el índice 0 (padding) en el conteo\n",
    "num_words_input = min(len(word2idx_inputs) + 1, MAX_VOCAB_SIZE)\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE)\n",
    "\n",
    "print(f\"info  del vocabulario:\")\n",
    "print(f\"- Palabras únicas en preguntas: {len(word2idx_inputs)}\")\n",
    "print(f\"- Palabras únicas en respuestas: {len(word2idx_outputs)}\")\n",
    "print(f\"- Vocabulario final inputs: {num_words_input}\")\n",
    "print(f\"- Vocabulario final outputs: {num_words_output}\")\n",
    "print(f\"- Longitud máxima real inputs: {max_input_len_real}\")\n",
    "print(f\"- Longitud máxima real outputs: {max_out_len_real}\")\n",
    "\n",
    "# Verificar que los tokens especiales estén presentes\n",
    "if '<sos>' in word2idx_outputs and '<eos>' in word2idx_outputs:\n",
    "    print(\" Tokens especiales <sos> y <eos> encontrados\")\n",
    "    print(f\"- Índice <sos>: {word2idx_outputs['<sos>']}\")\n",
    "    print(f\"- Índice <eos>: {word2idx_outputs['<eos>']}\")\n",
    "else:\n",
    "    print(\" ERROR: Tokens especiales no encontrados!\")\n",
    "\n",
    "\n",
    "# CONVERTIR TEXTO A SECUENCIAS NUMÉRICAS\n",
    "# ============================================================================\n",
    "\n",
    "# IMPORTANTE: Filtrar índices que excedan MAX_VOCAB_SIZE\n",
    "def filter_sequences(sequences, max_vocab):\n",
    "    \"\"\"Reemplaza índices >= max_vocab con 1 (palabra desconocida)\"\"\"\n",
    "    filtered = []\n",
    "    for seq in sequences:\n",
    "        filtered_seq = [idx if idx < max_vocab else 1 for idx in seq]\n",
    "        filtered.append(filtered_seq)\n",
    "    return filtered\n",
    "\n",
    "# Filtrar secuencias de entrada\n",
    "input_integer_seq_filtered = filter_sequences(input_integer_seq, MAX_VOCAB_SIZE)\n",
    "output_integer_seq_filtered = filter_sequences(output_integer_seq, MAX_VOCAB_SIZE)\n",
    "output_input_integer_seq_filtered = filter_sequences(output_input_integer_seq, MAX_VOCAB_SIZE)\n",
    "\n",
    "# ENCODER: Secuencias de entrada (preguntas)\n",
    "# Padding al INICIO para que las últimas palabras sean más relevantes\n",
    "encoder_input_sequences = pad_sequences(\n",
    "    input_integer_seq_filtered, \n",
    "    maxlen=max_input_len,\n",
    "    padding='pre'  # Padding al inicio\n",
    ")\n",
    "\n",
    "# DECODER INPUT: Secuencias que empiezan con <sos> \n",
    "# Padding al FINAL porque necesitamos la secuencia completa\n",
    "decoder_input_sequences = pad_sequences(\n",
    "    output_input_integer_seq_filtered,\n",
    "    maxlen=max_out_len, \n",
    "    padding='post'  # Padding al final\n",
    ")\n",
    "\n",
    "# DECODER OUTPUT: Secuencias que terminan con <eos>\n",
    "# Estas son los \"targets\" que el modelo debe predecir\n",
    "decoder_output_sequences = pad_sequences(\n",
    "    output_integer_seq_filtered,\n",
    "    maxlen=max_out_len,\n",
    "    padding='post'  # Padding al final\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# CREAR TARGETS EN FORMATO ONE-HOT\n",
    "# ======================================\n",
    "\n",
    "# Convirtiendo targets a formato one-hot\n",
    "# Verificación de seguridad: revisar el rango de índices\n",
    "max_idx_in_sequences = np.max(decoder_output_sequences)\n",
    "print(f\"\\nVerificación de índices:\")\n",
    "print(f\"- Índice máximo en secuencias: {max_idx_in_sequences}\")\n",
    "print(f\"- num_words_output: {num_words_output}\")\n",
    "\n",
    "# Ajustar num_classes si es necesario\n",
    "num_classes = max(num_words_output, max_idx_in_sequences + 1)\n",
    "print(f\"- num_classes ajustado: {num_classes}\")\n",
    "\n",
    "# Convertir las secuencias de salida a formato one-hot para la función de pérdida\n",
    "decoder_targets = to_categorical(\n",
    "    decoder_output_sequences, \n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "print(f\" Shape de targets one-hot: {decoder_targets.shape}\")\n",
    "print(f\"- Cada posición tiene {num_classes} clases posibles\")\n",
    "\n",
    "# Actualizar num_words_output para mantener consistencia\n",
    "num_words_output = num_classes\n",
    "\n",
    "# Crear diccionarios inversos para debugging\n",
    "idx2word_inputs = {v: k for k, v in word2idx_inputs.items()}\n",
    "idx2word_outputs = {v: k for k, v in word2idx_outputs.items()}\n",
    "\n",
    "print(\"\\n--- Verificación de diccionarios inversos ---\")\n",
    "print(f\"idx2word_inputs creado: {len(idx2word_inputs)} palabras\")\n",
    "print(f\"idx2word_outputs creado: {len(idx2word_outputs)} palabras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Descargando embeddings GloVe ---\n",
      "gloveembedding.pkl ya está disponible\n",
      "\n",
      "--- Implementando clases para embeddings ---\n",
      "\n",
      "--- Cargando modelo GloVe ---\n",
      "Inicializando GloVe embeddings...\n",
      "Cargando embeddings desde gloveembedding.pkl\n",
      "Embeddings cargados: 1193514 palabras, 50 dimensiones\n",
      "Configuración de embeddings:\n",
      "- Dimensiones: 50\n",
      "- Vocabulario total: 1193514\n",
      "- Archivo fuente: gloveembedding.pkl\n",
      "Variables disponibles:\n",
      "- num_words_input: 1800\n",
      "- Tamaño del vocabulario de entrada: 1799\n",
      "Creando matriz de embeddings 1800 x 50...\n",
      " Estadísticas de embedding matrix:\n",
      "- Shape final: (1800, 50)\n",
      "- Palabras encontradas en GloVe: 1799/1799 (100.0%)\n",
      "- Palabras no encontradas: 0\n",
      "- Embeddings nulos: 139\n",
      "\n",
      "--- Verificaciones de embeddings ---\n",
      "Probando palabras comunes:\n",
      "  'hello' (idx=19): Encontrada (norma=4.874)\n",
      "  'good' (idx=24): Encontrada (norma=6.277)\n",
      "  'how' (idx=10): Encontrada (norma=6.528)\n",
      "  'you' (idx=2): Encontrada (norma=7.152)\n",
      "  'are' (idx=7): Encontrada (norma=7.063)\n",
      "  'what' (idx=4): Encontrada (norma=6.498)\n",
      "\n",
      "--- Preparando capa de Embedding ---\n",
      "Capa de embedding creada:\n",
      "- input_dim: 1800\n",
      "- output_dim: 50\n",
      "- input_length: 10\n",
      "- trainable: False (embeddings congelados)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "#  PREPARAR EMBEDDINGS ----- GLOVE\n",
    "# ============================================================================\n",
    "\n",
    "# Imports necesarios para embeddings\n",
    "import os\n",
    "import gdown\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DESCARGAR EMBEDDINGS GLOVE PRE-ENTRENADOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- Descargando embeddings GloVe ---\")\n",
    "\n",
    "# Descargar embeddings GloVe 50d desde Google Drive\n",
    "if not os.access('gloveembedding.pkl', os.F_OK):\n",
    "    print(\"Descargando gloveembedding.pkl...\")\n",
    "    url = 'https://drive.google.com/uc?id=1KY6avD5I1eI2dxQzMkR3WExwKwRq2g94&export=download'\n",
    "    output = 'gloveembedding.pkl'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "    print(\"Descarga completada\")\n",
    "else:\n",
    "    print(\"gloveembedding.pkl ya está disponible\")\n",
    "\n",
    "\n",
    "# IMPLEMENTAR CLASES PARA MANEJAR EMBEDDINGS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- Implementando clases para embeddings ---\")\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    \"\"\"Clase base para manejar embeddings de palabras\"\"\"\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # Cargar embeddings desde archivo pickle o texto\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        \n",
    "        if not words_embedding_pkl.is_file():\n",
    "            # Si no existe el pickle, buscar archivo de texto original\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), f'Words embedding not available at {self.WORD_TO_VEC_MODEL_TXT_PATH}'\n",
    "            print(f\"Convirtiendo {self.WORD_TO_VEC_MODEL_TXT_PATH} a pickle...\")\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            # Cargar desde pickle pre-existente\n",
    "            print(f\"Cargando embeddings desde {self.PKL_PATH}\")\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "            \n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        # Construir mapeos palabra <-> índice\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "        \n",
    "        print(f\"Embeddings cargados: {len(self.embeddings)} palabras, {self.N_FEATURES} dimensiones\")\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        \"\"\"Obtener vectores de embedding para una lista de palabras\"\"\"\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        \"\"\"Convertir palabras a índices\"\"\"\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        \"\"\"Convertir índices a palabras\"\"\"\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        \"\"\"Cargar embeddings desde archivo pickle\"\"\"\n",
    "        self.logger.debug(f'Loading embeddings from pickle {self.PKL_PATH}')\n",
    "        \n",
    "        # Manejo de archivos grandes (hasta 256MB por chunk)\n",
    "        max_bytes = 2**28 - 1\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        \n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "                \n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('Embeddings loaded successfully')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        \"\"\"Convertir archivo de texto a formato pickle para carga rápida\"\"\"\n",
    "        self.logger.debug(f'Converting embeddings from {self.WORD_TO_VEC_MODEL_TXT_PATH}')\n",
    "        \n",
    "        # Crear estructura de array NumPy: palabra + vector de embeddings\n",
    "        structure = [\n",
    "            ('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "            ('embedding', np.float32, (self.N_FEATURES,))\n",
    "        ]\n",
    "        structure = np.dtype(structure)\n",
    "        \n",
    "        # Cargar desde archivo de texto usando generador (eficiente en memoria)\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) \n",
    "                for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "            \n",
    "        # Agregar embedding nulo para palabras desconocidas\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        \n",
    "        # Guardar como pickle para cargas futuras más rápidas\n",
    "        max_bytes = 2**28 - 1\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "                \n",
    "        self.logger.debug('Embeddings converted and saved to pickle')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    \"\"\"Implementación específica para embeddings GloVe 50d\"\"\"\n",
    "    \n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'  # Archivo original (si fuera necesario)\n",
    "    PKL_PATH = 'gloveembedding.pkl'  # Archivo pickle descargado\n",
    "    N_FEATURES = 50                  # Dimensiones del embedding\n",
    "    WORD_MAX_SIZE = 60              # Longitud máxima de palabras\n",
    "\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    \"\"\"Implementación para FastText (disponible para futura experimentación)\"\"\"\n",
    "    \n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "\n",
    "# CARGAR MODELO GLOVE\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n--- Cargando modelo GloVe ---\")\n",
    "\n",
    "# Configuración de logging para debugging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Cargar embeddings GloVe 50d\n",
    "print(\"Inicializando GloVe embeddings...\")\n",
    "model_embeddings = GloveEmbeddings()\n",
    "\n",
    "# Configuración de embeddings para el modelo\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "print(f\"Configuración de embeddings:\")\n",
    "print(f\"- Dimensiones: {embed_dim}\")\n",
    "print(f\"- Vocabulario total: {len(model_embeddings.embeddings)}\")\n",
    "print(f\"- Archivo fuente: {model_embeddings.PKL_PATH}\")\n",
    "\n",
    "\n",
    "# CREAR EMBEDDING MATRIX PARA EL VOCABULARIO\n",
    "# =================================================================\n",
    "\n",
    "\n",
    "# Variables del preprocesamiento (deben estar disponibles de la Etapa 1)\n",
    "print(f\"Variables disponibles:\")\n",
    "print(f\"- num_words_input: {num_words_input}\")\n",
    "print(f\"- Tamaño del vocabulario de entrada: {len(word2idx_inputs)}\")\n",
    "\n",
    "# Inicializar matriz de embeddings\n",
    "# MAX_VOCAB_SIZE=4000 palabras x 50 dimensiones\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs))+1\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "words_not_found = []\n",
    "\n",
    "\"\"\" \n",
    "porque + 1 -> nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs))+1\n",
    "EEERRROO\n",
    "len(word2idx_inputs) = 1799 palabras únicas\n",
    "MAX_VOCAB_SIZE = 4000  # ok-- Esto está bien (es el límite máximo)\n",
    "\n",
    "# El cálculo era:\n",
    "nb_words = min(4000, 1799) = 1799  # ERROR-- Problema aquí\n",
    "\n",
    "# Pero el tokenizer usa índices 1-1799\n",
    "# La embedding esperaba rango 0-1798\n",
    "# Resultado: índice 1799 está fuera de rango\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Creando matriz de embeddings {nb_words} x {embed_dim}...\")\n",
    "\n",
    "# Llenar matriz con embeddings pre-entrenados\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "        \n",
    "    # Obtener vector de embedding para la palabra\n",
    "    embedding_vector = model_embeddings.get_words_embeddings([word])[0]\n",
    "    \n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        # Si la palabra existe en GloVe, usar su vector\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # Si no existe, quedará como vector de ceros\n",
    "        words_not_found.append(word)\n",
    "\n",
    "# Estadísticas de cobertura\n",
    "total_words = len(word2idx_inputs)\n",
    "found_words = total_words - len(words_not_found)\n",
    "coverage = (found_words / total_words) * 100\n",
    "\n",
    "print(f\" Estadísticas de embedding matrix:\")\n",
    "print(f\"- Shape final: {embedding_matrix.shape}\")\n",
    "print(f\"- Palabras encontradas en GloVe: {found_words}/{total_words} ({coverage:.1f}%)\")\n",
    "print(f\"- Palabras no encontradas: {len(words_not_found)}\")\n",
    "print(f\"- Embeddings nulos: {np.sum(np.sum(embedding_matrix**2, axis=1) == 0)}\")\n",
    "\n",
    "\n",
    "# VERIFICACIONES Y EJEMPLOS\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n--- Verificaciones de embeddings ---\")\n",
    "\n",
    "# Probar algunas palabras comunes\n",
    "test_words = ['hello', 'good', 'how', 'you', 'are', 'what']\n",
    "print(\"Probando palabras comunes:\")\n",
    "\n",
    "for word in test_words:\n",
    "    if word in word2idx_inputs:\n",
    "        idx = word2idx_inputs[word]\n",
    "        if idx < nb_words:\n",
    "            vector_norm = np.linalg.norm(embedding_matrix[idx])\n",
    "            status = \"Encontrada\" if vector_norm > 0 else \" No encontrada\"\n",
    "            print(f\"  '{word}' (idx={idx}): {status} (norma={vector_norm:.3f})\")\n",
    "    else:\n",
    "        print(f\"  '{word}':  No está en vocabulario\")\n",
    "\n",
    "# Mostrar algunas palabras no encontradas (si las hay)\n",
    "if words_not_found:\n",
    "    print(f\"\\nPrimeras 10 palabras no encontradas en GloVe:\")\n",
    "    for word in words_not_found[:10]:\n",
    "        print(f\"  - '{word}'\")\n",
    "\n",
    "# PREPARAR CAPA DE EMBEDDING PARA KERAS\n",
    "# ===================================\n",
    "\n",
    "print(\"\\n--- Preparando capa de Embedding ---\")\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# Crear capa de embedding con pesos pre-entrenados\n",
    "encoder_embedding_layer = Embedding(\n",
    "    input_dim=nb_words,              # Tamaño del vocabulario\n",
    "    output_dim=embed_dim,            # Dimensiones del embedding (50)\n",
    "    input_length=max_input_len,      # Longitud máxima de secuencias\n",
    "    weights=[embedding_matrix],      # Matriz de embeddings pre-entrenados\n",
    "    trainable=False,                 # No entrenar los embeddings (usar como están)\n",
    "    name='encoder_embedding'\n",
    ")\n",
    "\n",
    "print(f\"Capa de embedding creada:\")\n",
    "print(f\"- input_dim: {nb_words}\")\n",
    "print(f\"- output_dim: {embed_dim}\")\n",
    "print(f\"- input_length: {max_input_len}\")\n",
    "print(f\"- trainable: False (embeddings congelados)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RESUMEN DEL MODELO:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2seq_qa_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"seq2seq_qa_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">90,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">115,648</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │ encoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ decoder_embeddin… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1807</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">117,455</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)    │     \u001b[38;5;34m90,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │    \u001b[38;5;34m115,648\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m29,440\u001b[0m │ encoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m),  │     \u001b[38;5;34m33,024\u001b[0m │ decoder_embeddin… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1807\u001b[0m)  │    \u001b[38;5;34m117,455\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385,567</span> (1.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m385,567\u001b[0m (1.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">295,567</span> (1.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m295,567\u001b[0m (1.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,000</span> (351.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m90,000\u001b[0m (351.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Diagrama guardado: seq2seq_model.png\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Diagramas de inferencia guardados\n",
      "\n",
      "--- INICIANDO ENTRENAMIENTO ---\n",
      " Entrenando con 6033 ejemplos...\n",
      "Datos de entrenamiento: 4826\n",
      "Datos de validación: 1207\n",
      "\n",
      "Verificación de datos:\n",
      "- encoder_input_sequences shape: (6033, 10)\n",
      "- decoder_input_sequences shape: (6033, 12)\n",
      "- decoder_targets shape: (6033, 12, 1807)\n",
      "\n",
      "Iniciando entrenamiento por 50 épocas...\n",
      "Epoch 1/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.5321 - loss: 4.8959 - val_accuracy: 0.6553 - val_loss: 2.0018\n",
      "Epoch 2/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6635 - loss: 1.8904 - val_accuracy: 0.6936 - val_loss: 1.8330\n",
      "Epoch 3/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6818 - loss: 1.7295 - val_accuracy: 0.7054 - val_loss: 1.7572\n",
      "Epoch 4/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6986 - loss: 1.6354 - val_accuracy: 0.7213 - val_loss: 1.6890\n",
      "Epoch 5/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7368 - loss: 1.5178 - val_accuracy: 0.7348 - val_loss: 1.6296\n",
      "Epoch 6/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7456 - loss: 1.4420 - val_accuracy: 0.7420 - val_loss: 1.5839\n",
      "Epoch 7/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7540 - loss: 1.3900 - val_accuracy: 0.7441 - val_loss: 1.5480\n",
      "Epoch 8/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7594 - loss: 1.3323 - val_accuracy: 0.7497 - val_loss: 1.5229\n",
      "Epoch 9/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7695 - loss: 1.2724 - val_accuracy: 0.7532 - val_loss: 1.5006\n",
      "Epoch 10/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7732 - loss: 1.2490 - val_accuracy: 0.7551 - val_loss: 1.4801\n",
      "Epoch 11/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7795 - loss: 1.1969 - val_accuracy: 0.7592 - val_loss: 1.4602\n",
      "Epoch 12/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7823 - loss: 1.1834 - val_accuracy: 0.7633 - val_loss: 1.4465\n",
      "Epoch 13/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7836 - loss: 1.1751 - val_accuracy: 0.7645 - val_loss: 1.4312\n",
      "Epoch 14/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7876 - loss: 1.1376 - val_accuracy: 0.7673 - val_loss: 1.4225\n",
      "Epoch 15/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7890 - loss: 1.1201 - val_accuracy: 0.7681 - val_loss: 1.4116\n",
      "Epoch 16/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7949 - loss: 1.0907 - val_accuracy: 0.7702 - val_loss: 1.4013\n",
      "Epoch 17/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7988 - loss: 1.0599 - val_accuracy: 0.7715 - val_loss: 1.3970\n",
      "Epoch 18/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8029 - loss: 1.0272 - val_accuracy: 0.7710 - val_loss: 1.3915\n",
      "Epoch 19/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7988 - loss: 1.0429 - val_accuracy: 0.7729 - val_loss: 1.3868\n",
      "Epoch 20/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8026 - loss: 1.0125 - val_accuracy: 0.7727 - val_loss: 1.3813\n",
      "Epoch 21/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8032 - loss: 0.9997 - val_accuracy: 0.7739 - val_loss: 1.3785\n",
      "Epoch 22/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8047 - loss: 0.9853 - val_accuracy: 0.7745 - val_loss: 1.3797\n",
      "Epoch 23/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8069 - loss: 0.9673 - val_accuracy: 0.7742 - val_loss: 1.3756\n",
      "Epoch 24/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8076 - loss: 0.9657 - val_accuracy: 0.7746 - val_loss: 1.3762\n",
      "Epoch 25/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8081 - loss: 0.9515 - val_accuracy: 0.7747 - val_loss: 1.3749\n",
      "Epoch 26/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8067 - loss: 0.9410 - val_accuracy: 0.7756 - val_loss: 1.3720\n",
      "Epoch 27/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8100 - loss: 0.9355 - val_accuracy: 0.7763 - val_loss: 1.3730\n",
      "Epoch 28/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8103 - loss: 0.9175 - val_accuracy: 0.7749 - val_loss: 1.3739\n",
      "Epoch 29/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8103 - loss: 0.9153 - val_accuracy: 0.7778 - val_loss: 1.3734\n",
      "Epoch 30/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8113 - loss: 0.9041 - val_accuracy: 0.7763 - val_loss: 1.3751\n",
      "Epoch 31/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8135 - loss: 0.8879 - val_accuracy: 0.7767 - val_loss: 1.3766\n",
      "Epoch 32/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8130 - loss: 0.8945 - val_accuracy: 0.7768 - val_loss: 1.3730\n",
      "Epoch 33/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8152 - loss: 0.8724 - val_accuracy: 0.7771 - val_loss: 1.3764\n",
      "Epoch 34/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8174 - loss: 0.8603 - val_accuracy: 0.7783 - val_loss: 1.3753\n",
      "Epoch 35/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8149 - loss: 0.8627 - val_accuracy: 0.7777 - val_loss: 1.3789\n",
      "Epoch 36/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8182 - loss: 0.8479 - val_accuracy: 0.7791 - val_loss: 1.3791\n",
      "Epoch 37/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8197 - loss: 0.8309 - val_accuracy: 0.7783 - val_loss: 1.3816\n",
      "Epoch 38/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8203 - loss: 0.8235 - val_accuracy: 0.7793 - val_loss: 1.3843\n",
      "Epoch 39/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8202 - loss: 0.8252 - val_accuracy: 0.7794 - val_loss: 1.3862\n",
      "Epoch 40/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8200 - loss: 0.8211 - val_accuracy: 0.7793 - val_loss: 1.3896\n",
      "Epoch 41/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8217 - loss: 0.8108 - val_accuracy: 0.7798 - val_loss: 1.3887\n",
      "Epoch 42/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8196 - loss: 0.8127 - val_accuracy: 0.7790 - val_loss: 1.3938\n",
      "Epoch 43/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8241 - loss: 0.7964 - val_accuracy: 0.7796 - val_loss: 1.3947\n",
      "Epoch 44/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8235 - loss: 0.7990 - val_accuracy: 0.7802 - val_loss: 1.4000\n",
      "Epoch 45/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8225 - loss: 0.7863 - val_accuracy: 0.7811 - val_loss: 1.4032\n",
      "Epoch 46/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8269 - loss: 0.7658 - val_accuracy: 0.7809 - val_loss: 1.4025\n",
      "Epoch 47/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8281 - loss: 0.7640 - val_accuracy: 0.7815 - val_loss: 1.4089\n",
      "Epoch 48/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8282 - loss: 0.7547 - val_accuracy: 0.7811 - val_loss: 1.4126\n",
      "Epoch 49/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8287 - loss: 0.7501 - val_accuracy: 0.7811 - val_loss: 1.4130\n",
      "Epoch 50/50\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8298 - loss: 0.7490 - val_accuracy: 0.7793 - val_loss: 1.4145\n",
      "¡ENTRENAMIENTO COMPLETADO!\n",
      "\n",
      "--- Visualizando resultados ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ESTADÍSTICAS FINALES:\n",
      "Accuracy final:\n",
      "  - Entrenamiento: 0.8291 (82.91%)\n",
      "  - Validación: 0.7793 (77.93%)\n",
      "Loss final:\n",
      "  - Entrenamiento: 0.7541\n",
      "  - Validación: 1.4145\n",
      "Modelo balanceado (diferencia: 0.0498)\n",
      "El modelo ha aprendido de 6033 conversaciones\n",
      "Accuracy de validación: 77.93%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENTRENAR MODELO ENCODER-DECODER\n",
    "# ============================================================================\n",
    "\n",
    "# Imports necesarios para el modelo\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# CONFIGURACIÓN DE HIPERPARÁMETROS DEL MODELO\n",
    "# ============================================================================\n",
    "# Configuración de la red neuronal\n",
    "n_units = 64               # Unidades LSTM (empezar conservador)\n",
    "epochs = 50                # Número de épocas de entrenamiento\n",
    "batch_size = 32            # Tamaño del batch\n",
    "validation_split = 0.2     # 20% para validación\n",
    "\n",
    "\n",
    "# ENCODER: Procesa las preguntas de entrada\n",
    "# ====================\n",
    "\n",
    "\n",
    "# Input del encoder: secuencias de preguntas\n",
    "encoder_inputs = Input(shape=(max_input_len,), name='encoder_inputs')\n",
    "\n",
    "# Capa de embedding (ya preparada en Etapa 2)\n",
    "encoder_inputs_embedded = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "\n",
    "# LSTM del encoder: procesa la secuencia y retorna estados finales\n",
    "encoder_lstm = LSTM(\n",
    "    n_units, \n",
    "    return_state=True,        # Retornar estados h y c\n",
    "    dropout=0.2,              # Dropout para regularización\n",
    "    recurrent_dropout=0.2,    # Dropout en conexiones recurrentes\n",
    "    name='encoder_lstm'\n",
    ")\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs_embedded)\n",
    "encoder_states = [state_h, state_c]  # Estados que se pasan al decoder\n",
    "\n",
    "# DECODER: Genera las respuestas\n",
    "# Input del decoder: secuencias que empiezan con <sos>\n",
    "decoder_inputs = Input(shape=(max_out_len,), name='decoder_inputs')\n",
    "\n",
    "\n",
    "# Embedding layer para el decoder (se entrena desde cero)\n",
    "decoder_embedding_layer = Embedding(\n",
    "    input_dim=num_words_output,\n",
    "    output_dim=n_units,           # Misma dimensión que LSTM\n",
    "    input_length=max_out_len,\n",
    "    trainable=True,               # Esta sí se entrena\n",
    "    name='decoder_embedding'\n",
    ")\n",
    "\n",
    "decoder_inputs_embedded = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "\n",
    "# LSTM del decoder: usa los estados del encoder como estado inicial\n",
    "decoder_lstm = LSTM(\n",
    "    n_units,\n",
    "    return_sequences=True,        # Retornar secuencia completa\n",
    "    return_state=True,            # También retornar estados\n",
    "    dropout=0.2,\n",
    "    recurrent_dropout=0.2,\n",
    "    name='decoder_lstm'\n",
    ")\n",
    "\n",
    "# El decoder usa los estados del encoder como punto de partida\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "    decoder_inputs_embedded, \n",
    "    initial_state=encoder_states  # ¡Aquí está la magia del seq2seq!\n",
    ")\n",
    "\n",
    "\n",
    "# Capa densa final: convierte estados LSTM a distribución de probabilidades\n",
    "decoder_dense = Dense(\n",
    "    num_words_output, \n",
    "    activation='softmax',\n",
    "    name='decoder_dense'\n",
    ")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "# MODELO COMPLETO: Para entrenamiento\n",
    "# Modelo que conecta entradas con salidas. Modelo seq2seq creado\n",
    "model = Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs],\n",
    "    outputs=decoder_outputs,\n",
    "    name='seq2seq_qa_model'\n",
    ")\n",
    "\n",
    "\n",
    "#  COMPILAR EL MODELO\n",
    "# ====================\n",
    "\n",
    "# Configurar función de pérdida y optimizador\n",
    "model.compile(\n",
    "    optimizer='adam',                    # Optimizador Adam (adaptativo)\n",
    "    loss='categorical_crossentropy',     # Pérdida para clasificación multiclase\n",
    "    metrics=['accuracy']                 # Métrica para monitorear progreso\n",
    ")\n",
    "\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "print(\"\\n RESUMEN DEL MODELO:\")\n",
    "model.summary()\n",
    "\n",
    "# CREAR MODELOS PARA INFERENCIA (PREPARAR PARA ETAPA 5)\n",
    "# =================================\n",
    "\n",
    "# ENCODER MODEL: Solo para extraer estados\n",
    "\n",
    "\n",
    "encoder_model = Model(\n",
    "    inputs=encoder_inputs, \n",
    "    outputs=encoder_states,\n",
    "    name='encoder_inference'\n",
    ")\n",
    "\n",
    "\n",
    "# DECODER MODEL: Para generación palabra por palabra\n",
    "\n",
    "\n",
    "# Inputs para los estados del decoder\n",
    "decoder_state_input_h = Input(shape=(n_units,), name='decoder_state_h')\n",
    "decoder_state_input_c = Input(shape=(n_units,), name='decoder_state_c')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Input para una sola palabra (durante inferencia)\n",
    "decoder_inputs_single = Input(shape=(1,), name='decoder_single_input')\n",
    "decoder_inputs_single_embedded = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "# LSTM del decoder para inferencia\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(\n",
    "    decoder_inputs_single_embedded, \n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states_inf = [state_h_inf, state_c_inf]\n",
    "\n",
    "# Capa densa final\n",
    "decoder_outputs_inf = decoder_dense(decoder_outputs_inf)\n",
    "\n",
    "# Modelo del decoder para inferencia\n",
    "decoder_model = Model(\n",
    "    inputs=[decoder_inputs_single] + decoder_states_inputs,\n",
    "    outputs=[decoder_outputs_inf] + decoder_states_inf,\n",
    "    name='decoder_inference'\n",
    ")\n",
    "\n",
    "#  VISUALIZAR ARQUITECTURA\n",
    "# ===\n",
    "\n",
    "try:\n",
    "    # Diagrama del modelo completo\n",
    "    plot_model(model, to_file='seq2seq_model.png', show_shapes=True, show_layer_names=True)\n",
    "    print(\"Diagrama guardado: seq2seq_model.png\")\n",
    "    \n",
    "    # Diagramas de los modelos de inferencia\n",
    "    plot_model(encoder_model, to_file='encoder_model.png', show_shapes=True, show_layer_names=True)\n",
    "    plot_model(decoder_model, to_file='decoder_model.png', show_shapes=True, show_layer_names=True)\n",
    "    print(\"Diagramas de inferencia guardados\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Graphviz no disponible, diagramas no generados\")\n",
    "\n",
    "# ENTRENAR EL MODELO\n",
    "# ============================================================================\n",
    "print(\"\\n--- INICIANDO ENTRENAMIENTO ---\")\n",
    "print(f\" Entrenando con {len(encoder_input_sequences)} ejemplos...\")\n",
    "print(f\"Datos de entrenamiento: {len(encoder_input_sequences) * (1-validation_split):.0f}\")\n",
    "print(f\"Datos de validación: {len(encoder_input_sequences) * validation_split:.0f}\")\n",
    "\n",
    "# Verificar que los datos estén listos\n",
    "print(f\"\\nVerificación de datos:\")\n",
    "print(f\"- encoder_input_sequences shape: {encoder_input_sequences.shape}\")\n",
    "print(f\"- decoder_input_sequences shape: {decoder_input_sequences.shape}\")\n",
    "print(f\"- decoder_targets shape: {decoder_targets.shape}\")\n",
    "\n",
    "# ¡ENTRENAR EL MODELO!\n",
    "print(f\"\\nIniciando entrenamiento por {epochs} épocas...\")\n",
    "\n",
    "hist = model.fit(\n",
    "    x=[encoder_input_sequences, decoder_input_sequences],  # Entradas\n",
    "    y=decoder_targets,                                      # Targets (one-hot)\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,                      # 20% para validación\n",
    "    verbose=1                                              # Mostrar progreso\n",
    ")\n",
    "\n",
    "print(\"¡ENTRENAMIENTO COMPLETADO!\")\n",
    "\n",
    "#  VISUALIZAR RESULTADOS DEL ENTRENAMIENTO\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n--- Visualizando resultados ---\")\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "plt.style.use('default')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gráfico de Accuracy\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "ax1.plot(epoch_count, hist.history['accuracy'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "ax1.plot(epoch_count, hist.history['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de Loss\n",
    "ax2.plot(epoch_count, hist.history['loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "ax2.plot(epoch_count, hist.history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ESTADÍSTICAS FINALES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nESTADÍSTICAS FINALES:\")\n",
    "# Obtener métricas finales\n",
    "final_train_acc = hist.history['accuracy'][-1]\n",
    "final_val_acc = hist.history['val_accuracy'][-1]\n",
    "final_train_loss = hist.history['loss'][-1]\n",
    "final_val_loss = hist.history['val_loss'][-1]\n",
    "\n",
    "print(f\"Accuracy final:\")\n",
    "print(f\"  - Entrenamiento: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)\")\n",
    "print(f\"  - Validación: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)\")\n",
    "print(f\"Loss final:\")\n",
    "print(f\"  - Entrenamiento: {final_train_loss:.4f}\")\n",
    "print(f\"  - Validación: {final_val_loss:.4f}\")\n",
    "\n",
    "# Evaluar overfitting\n",
    "acc_diff = final_train_acc - final_val_acc\n",
    "if acc_diff > 0.1:\n",
    "    print(f\"Posible overfitting detectado (diferencia: {acc_diff:.4f})\")\n",
    "else:\n",
    "    print(f\"Modelo balanceado (diferencia: {acc_diff:.4f})\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"El modelo ha aprendido de {len(encoder_input_sequences)} conversaciones\")\n",
    "print(f\"Accuracy de validación: {final_val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función generate_response implementada\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# INFERENCIA - EXPERIMENTAR CON EL QA BOT\n",
    "# ===========================\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "#  FUNCIÓN DE TRADUCCIÓN/GENERACIÓN DE RESPUESTAS\n",
    "# =======================================================\n",
    "def generate_response(input_text, max_response_length=None):\n",
    "    \"\"\"\n",
    "    Generar respuesta del bot dada una pregunta de entrada\n",
    "    \n",
    "    Args:\n",
    "        input_text (str): Pregunta del usuario\n",
    "        max_response_length (int): Longitud máxima de respuesta (opcional)\n",
    "    \n",
    "    Returns:\n",
    "        str: Respuesta generada por el bot\n",
    "    \"\"\"\n",
    "    if max_response_length is None:\n",
    "        max_response_length = max_out_len\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Preprocesar la entrada (igual que en entrenamiento)\n",
    "    # ========================================================================\n",
    "    \n",
    "    ## Limpiar texto de entrada (usar la misma función de la Etapa 1)\n",
    "    #def clean_input_text(txt):\n",
    "    #    txt = txt.lower()\n",
    "    #    txt = txt.replace(\"'d\", \" had\")\n",
    "    #    txt = txt.replace(\"'s\", \" is\")\n",
    "    #    txt = txt.replace(\"'m\", \" am\")\n",
    "    #    txt = txt.replace(\"don't\", \"do not\")\n",
    "    #    # Eliminar caracteres no alfanuméricos\n",
    "    #    import re\n",
    "    #    txt = re.sub(r'\\W+', ' ', txt)\n",
    "    #    return txt.strip()\n",
    "    #\n",
    "    ## Limpiar y tokenizar la entrada\n",
    "    #cleaned_input = clean_input_text(input_text)\n",
    "    cleaned_input = clean_text(input_text)\n",
    "    \n",
    "    print(f\" Entrada limpia: '{cleaned_input}'\")\n",
    "    \n",
    "    # Convertir a secuencia de índices\n",
    "    input_sequence = input_tokenizer.texts_to_sequences([cleaned_input])[0]\n",
    "    print(f\"Secuencia tokenizada: {input_sequence}\")\n",
    "    \n",
    "    # Si la secuencia está vacía, usar secuencia por defecto\n",
    "    if not input_sequence:\n",
    "        print(\"ecuencia vacía, usando tokens por defecto\")\n",
    "        input_sequence = [1]  # Token genérico\n",
    "    \n",
    "    # Aplicar padding (mismo que en entrenamiento)\n",
    "    from tensorflow.keras.utils import pad_sequences\n",
    "    encoder_input_seq = pad_sequences(\n",
    "        [input_sequence], \n",
    "        maxlen=max_input_len,\n",
    "        padding='pre'\n",
    "    )\n",
    "    print(f\"Secuencia con padding: {encoder_input_seq}\")\n",
    "    \n",
    "    # Usar el encoder para obtener estados iniciales\n",
    "   \n",
    "    # El encoder convierte la pregunta en estados internos\n",
    "    states_value = encoder_model.predict(encoder_input_seq, verbose=0)\n",
    "    \n",
    "    print(f\" Estados del encoder obtenidos: {len(states_value)} estados\")\n",
    "    \n",
    "    #Generar respuesta palabra por palabra con el decoder\n",
    "    print(\" Generando respuesta...\")\n",
    "    \n",
    "    # Inicializar con token <sos> (start of sequence)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    if '<sos>' in word2idx_outputs:\n",
    "        target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    else:\n",
    "        target_seq[0, 0] = 1  # Fallback\n",
    "    \n",
    "    # Obtener índice de fin de secuencia\n",
    "    eos_idx = word2idx_outputs.get('<eos>', 2)  # Fallback a índice 2\n",
    "    \n",
    "    # Lista para almacenar las palabras generadas\n",
    "    generated_words = []\n",
    "    \n",
    "    # Generar palabra por palabra hasta <eos> o límite máximo\n",
    "    for step in range(max_response_length):\n",
    "        # Predecir próxima palabra y nuevos estados\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, \n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Obtener el índice de la palabra con mayor probabilidad\n",
    "        predicted_idx = np.argmax(output_tokens[0, 0, :])\n",
    "        \n",
    "        # Si llegamos al final de secuencia, parar\n",
    "        if predicted_idx == eos_idx:\n",
    "            print(f\"Fin de secuencia detectado en paso {step + 1}\")\n",
    "            break\n",
    "        \n",
    "        # Convertir índice a palabra\n",
    "        if predicted_idx > 0 and predicted_idx in idx2word_outputs:\n",
    "            predicted_word = idx2word_outputs[predicted_idx]\n",
    "            generated_words.append(predicted_word)\n",
    "            print(f\"  Paso {step + 1}: '{predicted_word}' (idx={predicted_idx})\")\n",
    "        else:\n",
    "            print(f\"  Paso {step + 1}: [DESCONOCIDO] (idx={predicted_idx})\")\n",
    "        \n",
    "        # Actualizar estados para la próxima iteración\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        # Actualizar entrada del decoder con la palabra recién generada\n",
    "        target_seq[0, 0] = predicted_idx\n",
    "    \n",
    "\n",
    "    # Construir respuesta final\n",
    "    if generated_words:\n",
    "        response = ' '.join(generated_words)\n",
    "        print(f\"Respuesta generada: '{response}'\")\n",
    "    else:\n",
    "        response = \"I don't understand\"  # Respuesta por defecto\n",
    "        print(f\"No se generaron palabras, usando respuesta por defecto\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"Función generate_response implementada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Probando con preguntas nuevas ---\n",
      "--- PREGUNTA 1 ---\n",
      " Usuario: Hello, how are you?\n",
      " Entrada limpia: 'hello how are you '\n",
      "Secuencia tokenizada: [19, 10, 7, 2]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  0 19 10  7  2]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'm' (idx=18)\n",
      "  Paso 3: 'fine' (idx=41)\n",
      "Fin de secuencia detectado en paso 4\n",
      "Respuesta generada: 'i m fine'\n",
      "Bot: i m fine\n",
      "\n",
      "--- PREGUNTA 2 ---\n",
      " Usuario: What is your name?\n",
      " Entrada limpia: 'what is your name '\n",
      "Secuencia tokenizada: [4, 15, 21, 51]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  0  4 15 21 51]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'am' (idx=12)\n",
      "  Paso 3: 'a' (idx=7)\n",
      "  Paso 4: 'girl' (idx=82)\n",
      "  Paso 5: 'i' (idx=4)\n",
      "  Paso 6: 'am' (idx=12)\n",
      "  Paso 7: 'a' (idx=7)\n",
      "  Paso 8: 'girl' (idx=82)\n",
      "Fin de secuencia detectado en paso 9\n",
      "Respuesta generada: 'i am a girl i am a girl'\n",
      "Bot: i am a girl i am a girl\n",
      "\n",
      "--- PREGUNTA 3 ---\n",
      " Usuario: Do you like music?\n",
      " Entrada limpia: 'do you like music '\n",
      "Secuencia tokenizada: [3, 2, 12, 96]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  0  3  2 12 96]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'like' (idx=14)\n",
      "  Paso 3: 'to' (idx=9)\n",
      "  Paso 4: 'play' (idx=50)\n",
      "  Paso 5: 'video' (idx=84)\n",
      "  Paso 6: 'games' (idx=74)\n",
      "Fin de secuencia detectado en paso 7\n",
      "Respuesta generada: 'i like to play video games'\n",
      "Bot: i like to play video games\n",
      "\n",
      "--- PREGUNTA 4 ---\n",
      " Usuario: Where are you from?\n",
      " Entrada limpia: 'where are you from '\n",
      "Secuencia tokenizada: [52, 7, 2, 39]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  0 52  7  2 39]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'am' (idx=12)\n",
      "  Paso 3: 'a' (idx=7)\n",
      "  Paso 4: 'big' (idx=218)\n",
      "  Paso 5: 'fan' (idx=244)\n",
      "  Paso 6: 'of' (idx=44)\n",
      "  Paso 7: 'the' (idx=27)\n",
      "  Paso 8: 'beatles' (idx=406)\n",
      "Fin de secuencia detectado en paso 9\n",
      "Respuesta generada: 'i am a big fan of the beatles'\n",
      "Bot: i am a big fan of the beatles\n",
      "\n",
      "--- PREGUNTA 5 ---\n",
      " Usuario: What do you do?\n",
      " Entrada limpia: 'what do you do '\n",
      "Secuencia tokenizada: [4, 3, 2, 3]\n",
      "Secuencia con padding: [[0 0 0 0 0 0 4 3 2 3]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'like' (idx=14)\n",
      "  Paso 3: 'to' (idx=9)\n",
      "  Paso 4: 'play' (idx=50)\n",
      "  Paso 5: 'video' (idx=84)\n",
      "  Paso 6: 'games' (idx=74)\n",
      "Fin de secuencia detectado en paso 7\n",
      "Respuesta generada: 'i like to play video games'\n",
      "Bot: i like to play video games\n",
      "\n",
      "--- PREGUNTA 6 ---\n",
      " Usuario: Do you have any hobbies?\n",
      " Entrada limpia: 'do you have any hobbies '\n",
      "Secuencia tokenizada: [3, 2, 16, 31, 48]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  3  2 16 31 48]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'like' (idx=14)\n",
      "  Paso 3: 'to' (idx=9)\n",
      "  Paso 4: 'play' (idx=50)\n",
      "  Paso 5: 'video' (idx=84)\n",
      "  Paso 6: 'games' (idx=74)\n",
      "Fin de secuencia detectado en paso 7\n",
      "Respuesta generada: 'i like to play video games'\n",
      "Bot: i like to play video games\n",
      "\n",
      "--- PREGUNTA 7 ---\n",
      " Usuario: How old are you?\n",
      " Entrada limpia: 'how old are you '\n",
      "Secuencia tokenizada: [10, 64, 7, 2]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  0 10 64  7  2]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'am' (idx=12)\n",
      "  Paso 3: 'doing' (idx=46)\n",
      "  Paso 4: 'well' (idx=54)\n",
      "  Paso 5: 'how' (idx=11)\n",
      "  Paso 6: 'are' (idx=8)\n",
      "  Paso 7: 'you' (idx=3)\n",
      "Fin de secuencia detectado en paso 8\n",
      "Respuesta generada: 'i am doing well how are you'\n",
      "Bot: i am doing well how are you\n",
      "\n",
      "--- PREGUNTA 8 ---\n",
      " Usuario: What's your favorite food?\n",
      " Entrada limpia: 'what s your favorite food '\n",
      "Secuencia tokenizada: [4, 30, 21, 62, 93]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  4 30 21 62 93]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'like' (idx=14)\n",
      "  Paso 3: 'to' (idx=9)\n",
      "  Paso 4: 'go' (idx=52)\n",
      "  Paso 5: 'to' (idx=9)\n",
      "  Paso 6: 'the' (idx=27)\n",
      "  Paso 7: 'beach' (idx=75)\n",
      "Fin de secuencia detectado en paso 8\n",
      "Respuesta generada: 'i like to go to the beach'\n",
      "Bot: i like to go to the beach\n",
      "\n",
      "--- PREGUNTA 9 ---\n",
      " Usuario: Do you have pets?\n",
      " Entrada limpia: 'do you have pets '\n",
      "Secuencia tokenizada: [3, 2, 16, 66]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  0  3  2 16 66]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'yes' (idx=30)\n",
      "Fin de secuencia detectado en paso 2\n",
      "Respuesta generada: 'yes'\n",
      "Bot: yes\n",
      "\n",
      "--- PREGUNTA 10 ---\n",
      " Usuario: What's the weather like?\n",
      " Entrada limpia: 'what s the weather like '\n",
      "Secuencia tokenizada: [4, 30, 26, 1722, 12]\n",
      "Secuencia con padding: [[   0    0    0    0    0    4   30   26 1722   12]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'am' (idx=12)\n",
      "  Paso 3: 'a' (idx=7)\n",
      "  Paso 4: 'girl' (idx=82)\n",
      "  Paso 5: 'i' (idx=4)\n",
      "  Paso 6: 'am' (idx=12)\n",
      "  Paso 7: 'a' (idx=7)\n",
      "  Paso 8: 'girl' (idx=82)\n",
      "Fin de secuencia detectado en paso 9\n",
      "Respuesta generada: 'i am a girl i am a girl'\n",
      "Bot: i am a girl i am a girl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  PRUEBAS  PREGUNTAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- Probando con preguntas nuevas ---\")\n",
    "\n",
    "# Lista de preguntas de prueba (no del dataset original)\n",
    "test_questions = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"What is your name?\",\n",
    "    \"Do you like music?\",\n",
    "    \"Where are you from?\",\n",
    "    \"What do you do?\",\n",
    "    \"Do you have any hobbies?\",\n",
    "    \"How old are you?\",\n",
    "    \"What's your favorite food?\",\n",
    "    \"Do you have pets?\",\n",
    "    \"What's the weather like?\"\n",
    "]\n",
    "\n",
    "\n",
    "for i, question in enumerate(test_questions):\n",
    "    print(f\"--- PREGUNTA {i + 1} ---\")\n",
    "    print(f\" Usuario: {question}\")\n",
    "    \n",
    "    try:\n",
    "        response = generate_response(question)\n",
    "        print(f\"Bot: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR : {str(e)}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBANDO EL QA BOT\n",
      "==================================================\n",
      "Usuario: Hello, do you have a name?\n",
      " Bot:  Entrada limpia: 'hello do you have a name '\n",
      "Secuencia tokenizada: [19, 3, 2, 16, 5, 51]\n",
      "Secuencia con padding: [[ 0  0  0  0 19  3  2 16  5 51]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'am' (idx=12)\n",
      "  Paso 3: 'a' (idx=7)\n",
      "  Paso 4: 'student' (idx=79)\n",
      "Fin de secuencia detectado en paso 5\n",
      "Respuesta generada: 'i am a student'\n",
      "i am a student\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PRUEBA SIMPLE - UNA PREGUNTA AL BOT\n",
    "# ============================================================================\n",
    "\n",
    "# Tu pregunta de prueba\n",
    "pregunta = \"Hello, do you have a name?\"\n",
    "\n",
    "print(\"PROBANDO EL QA BOT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Usuario: {pregunta}\")\n",
    "print(\" Bot: \", end=\"\")\n",
    "\n",
    "# Generar respuesta\n",
    "try:\n",
    "    respuesta = generate_response(pregunta)\n",
    "    print(respuesta)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBANDO EL QA BOT\n",
      "==================================================\n",
      "Usuario: Do you know any books to read?\n",
      "Bot:  Entrada limpia: 'do you know any books to read '\n",
      "Secuencia tokenizada: [3, 2, 57, 31, 126, 6, 23]\n",
      "Secuencia con padding: [[  0   0   0   3   2  57  31 126   6  23]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'like' (idx=14)\n",
      "  Paso 3: 'to' (idx=9)\n",
      "  Paso 4: 'read' (idx=20)\n",
      "Fin de secuencia detectado en paso 5\n",
      "Respuesta generada: 'i like to read'\n",
      "i like to read\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PRUEBA SIMPLE - UNA PREGUNTA AL BOT\n",
    "# ============================================================================\n",
    "\n",
    "# Tu pregunta de prueba\n",
    "pregunta = \"Do you know any books to read?\"\n",
    "\n",
    "print(\"PROBANDO EL QA BOT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Usuario: {pregunta}\")\n",
    "print(\"Bot: \", end=\"\")\n",
    "\n",
    "# Generar respuesta\n",
    "try:\n",
    "    respuesta = generate_response(pregunta)\n",
    "    print(respuesta)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBANDO EL QA BOT\n",
      "==================================================\n",
      "Usuario: where are you?\n",
      "Bot:  Entrada limpia: 'where are you '\n",
      "Secuencia tokenizada: [52, 7, 2]\n",
      "Secuencia con padding: [[ 0  0  0  0  0  0  0 52  7  2]]\n",
      " Estados del encoder obtenidos: 2 estados\n",
      " Generando respuesta...\n",
      "  Paso 1: 'i' (idx=4)\n",
      "  Paso 2: 'am' (idx=12)\n",
      "  Paso 3: 'doing' (idx=46)\n",
      "  Paso 4: 'well' (idx=54)\n",
      "  Paso 5: 'how' (idx=11)\n",
      "  Paso 6: 'are' (idx=8)\n",
      "  Paso 7: 'you' (idx=3)\n",
      "Fin de secuencia detectado en paso 8\n",
      "Respuesta generada: 'i am doing well how are you'\n",
      "i am doing well how are you\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PRUEBA SIMPLE - UNA PREGUNTA AL BOT\n",
    "# ============================================================================\n",
    "\n",
    "# Tu pregunta de prueba\n",
    "pregunta = \"where are you?\"\n",
    "\n",
    "print(\"PROBANDO EL QA BOT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Usuario: {pregunta}\")\n",
    "print(\"Bot: \", end=\"\")\n",
    "\n",
    "# Generar respuesta\n",
    "try:\n",
    "    respuesta = generate_response(pregunta)\n",
    "    print(respuesta)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
