{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3891435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpio todas las variables\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c5d2c1",
   "metadata": {},
   "source": [
    "#  Procesamiento de Lenguaje Natural (NLP) de AI\n",
    "### Consigna del desafío 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f428bcd",
   "metadata": {},
   "source": [
    "<b id=\"1\">Punto-1</b>. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos: Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
    "\n",
    "<b id=\"2\">Punto-2</b>. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación (f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial y ComplementNB.\n",
    "\n",
    "<b id=\"3\">Punto-3</b>. Transponer la matriz documento-término. De esa manera se obtiene una matriz término-documento que puede ser interpretada como una colección de vectorización de palabras. Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcc089",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e9bda",
   "metadata": {},
   "source": [
    "# Creación del DataSet de texto\n",
    "\n",
    "En este ejercicio estamos tomando el texto de 5 archivos cortos .txt que contienen distintos tipos de información. el objetivo es crear un solo archivos con los requerimientos mínimos de un dataframe para que el modelo lo pueda entender. \n",
    "\n",
    "Contenido de archivos txt\n",
    "- LOBO ESPACIAL WARHAMMER 40000 (novela)\n",
    "- Deepfake: Todo lo que necesitas saber al respecto (articulo de noticia)\n",
    "- Don Quijote (novela) \n",
    "- ¿Qué es la inteligencia artificial (IA)? (articulo de noticia) \n",
    "- Neuromante - William Gibson (novela) \n",
    "\n",
    "Los pasos para la preparación del Dataset \n",
    "1. Buscar información relevante como cantidad de palabras, párrafo, promedio. \n",
    "2. Generar Fragmentos del texto \n",
    "3. Asignación de etiquetas/clases\n",
    "\n",
    "Nota: para este caso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b38b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Estadísticas de los archivos de texto:\n",
      "\n",
      "Archivo: texto-1.txt\n",
      "  Palabras: 103027  (43.6% del total )\n",
      "  Párrafos: 1792\n",
      "  promedio_palabras_por_parrafo: 57.49\n",
      "----------------------------------------\n",
      "Archivo: texto-2.txt\n",
      "  Palabras: 5710  (2.4% del total )\n",
      "  Párrafos: 165\n",
      "  promedio_palabras_por_parrafo: 34.61\n",
      "----------------------------------------\n",
      "Archivo: texto-3.txt\n",
      "  Palabras: 29835  (12.6% del total )\n",
      "  Párrafos: 798\n",
      "  promedio_palabras_por_parrafo: 37.39\n",
      "----------------------------------------\n",
      "Archivo: texto-4.txt\n",
      "  Palabras: 4480  (1.9% del total )\n",
      "  Párrafos: 89\n",
      "  promedio_palabras_por_parrafo: 50.34\n",
      "----------------------------------------\n",
      "Archivo: texto-5.txt\n",
      "  Palabras: 93365  (39.5% del total )\n",
      "  Párrafos: 3129\n",
      "  promedio_palabras_por_parrafo: 29.84\n",
      "----------------------------------------\n",
      "\n",
      "*** Promedio TOTAL ***\n",
      "  Promedio de palabras entre todos los archivo: 47283\n",
      "  Promedio de párrafos entre todos los archivo: 1195\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def contar_palabras_y_parrafos(ruta_archivo):\n",
    "    with open(ruta_archivo, 'r', encoding='utf-8') as f:\n",
    "        texto = f.read()\n",
    "    \n",
    "    palabras = texto.split()\n",
    "    total_palabras = len(palabras)\n",
    "    \n",
    "    parrafos = [p for p in texto.split('\\n') if p.strip()]\n",
    "    total_parrafos = len(parrafos)\n",
    "    \n",
    "    promedio_palabras_por_parrafo = total_palabras / total_parrafos if total_parrafos > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"palabras\": total_palabras,\n",
    "        \"parrafos\": total_parrafos,\n",
    "        \"promedio_palabras_por_parrafo\": promedio_palabras_por_parrafo\n",
    "        \n",
    "    }\n",
    "\n",
    "def analizar_carpeta(ruta_carpeta):\n",
    "    resultados = {}\n",
    "    \n",
    "    for archivo in os.listdir(ruta_carpeta):\n",
    "        if archivo.endswith('.txt'):\n",
    "            ruta_completa = os.path.join(ruta_carpeta, archivo)\n",
    "            stats = contar_palabras_y_parrafos(ruta_completa)\n",
    "            resultados[archivo] = stats\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Ruta a tu carpeta con los archivos .txt\n",
    "ruta_carpeta = './DataSet/Lote-txt/'\n",
    "\n",
    "# Analizar carpeta\n",
    "resultados = analizar_carpeta(ruta_carpeta)\n",
    "\n",
    "# Calcular promedios\n",
    "total_palabras = sum(stats['palabras'] for stats in resultados.values())\n",
    "total_parrafos = sum(stats['parrafos'] for stats in resultados.values())\n",
    "archivos_count = len(resultados)\n",
    "promedio_palabras = total_palabras / archivos_count\n",
    "promedio_parrafos = total_parrafos / archivos_count\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\" Estadísticas de los archivos de texto:\\n\")\n",
    "for archivo, stats in resultados.items():\n",
    "    porcentaje_palabras = (stats['palabras'] / total_palabras) * 100\n",
    "    print(f\"Archivo: {archivo}\")\n",
    "    print(f\"  Palabras: {stats['palabras']}  ({porcentaje_palabras:.1f}% del total )\")\n",
    "    print(f\"  Párrafos: {stats['parrafos']}\")\n",
    "    print(f\"  promedio_palabras_por_parrafo: {stats['promedio_palabras_por_parrafo']:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n",
    "print(\"\\n*** Promedio TOTAL ***\")\n",
    "print(f\"  Promedio de palabras entre todos los archivo: {promedio_palabras:.0f}\")\n",
    "print(f\"  Promedio de párrafos entre todos los archivo: {promedio_parrafos:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f007b81",
   "metadata": {},
   "source": [
    "### Creación del DataSet\n",
    "\n",
    "El siguiente código esta personalizado para tomar 5 textos en archivo plano .txt que realizaran la creación del dataset utilizando la librería de panda en la generación de las etiquetas y el texto. \n",
    "\n",
    "\n",
    "| Sintaxis numpy| Sintaxis panda|\n",
    "|---|---|\n",
    "| `df_train.data` | `df_train['texto']` |\n",
    "| `df_train.target` | `df_train['etiqueta']` |\n",
    "| `newsgroups_train = fetch_20newsgroups(...)` | `df_train = df` |\n",
    "| `newsgroups_test = fetch_20newsgroups(...)` | `df_test = df` |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "En la creación del dataset tenemos que tomar en cuneta 2 valores muy importantes tam_fragmento y overlap pero antes repasemos las siguientes definiciones. \n",
    "\n",
    "- ETIQUETA/CLASE (Label/Class): Categoría o tipo al que pertenece un document, podemos utiliza la analogía de El género/tema del libro,  en este proyecto es :\n",
    "        - texto-1.txt: lobo_espacial\n",
    "        - texto-2.txt: deepfake\n",
    "        - texto-3.txt: don_quijote\n",
    "        - texto-4.txt: ia_articulo\n",
    "        - texto-5.txt: neuromante'\n",
    "- CORPUS: Conjunto completo de todos los Document / fragmentos de todos los archivos\n",
    "- Document : Unidad básica con un bloque de texto que se analiza independientemente, su analogía un párrafo o capítulo del libro. Técnicamente Una fila en un DataFrame, un vector en la matriz documento-término. Para definir un Document tenemos que indicar \n",
    "    - tam_fragmento (Fragment Size): Número de palabras que contiene cada documento/fragmento. ejemplo `fragmentos = fragmentar_texto(texto_limpio, tam_fragmento=300,` indicamos un bloque de 300 palabras. \n",
    "    - OVERLAP (Solapamiento): Número de palabras compartidas entre fragmentos consecutivos Ejemplo :\n",
    "\n",
    "\n",
    "|Sin Overlap (overlap=0):|       |                |                    |       |\n",
    "|----------------|--------       |  ---------     |   ---------         | ---- |\n",
    "|Texto original: | [1][2][3][4]  |[5][6][7][8][9] |[10][11][12]...      |\n",
    "|Fragmento 1:    |[1][2][3][4][5]|                |                     | (palabras 1-5)| \n",
    "|Fragmento 2:    |               |[6][7][8][9][10]|                     |  (palabras 6-10)|\n",
    "|Fragmento 3:    |               |                |[11][12][13][14][15] | (palabras 11-15) |\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "|Con Overlap=2 palabras:|        |          |           |       |\n",
    "|----------------|-------------- |-------- | ----------|  ---     |\n",
    "|Texto original: |[1][2][3][4][5]|[6][7][8]|[9][10][11]|[12]...|\n",
    "|Fragmento 1:    |[1][2][3] [4][5]||                     |  (palabras 1-5)|         \n",
    "|Fragmento 2:    |         [4][5]|[6][7][8]|           |  (palabras 4-8)← Repite 4,5|\n",
    "|Fragmento 3:    |                   [7][8]|[9][10][11]|  (palabras 7-11) ← Repite 7,8|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5a4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++ Creación del Dataframe +++++++++++++++++++++\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def leer_archivos_txt(directorio):\n",
    "    \"\"\"\n",
    "    Lee todos los archivos .txt del directorio especificado\n",
    "    \"\"\"\n",
    "    archivos_datos = {}\n",
    "    \n",
    "    # Mapeo de nombres de archivo a etiquetas / Clases\n",
    "    mapeo_etiquetas = {\n",
    "        'texto-1.txt': 'lobo_espacial',\n",
    "        'texto-2.txt': 'deepfake', \n",
    "        'texto-3.txt': 'don_quijote',\n",
    "        'texto-4.txt': 'ia_articulo',\n",
    "        'texto-5.txt': 'neuromante'\n",
    "    }\n",
    "    \n",
    "    for archivo in os.listdir(directorio):\n",
    "        if archivo.endswith('.txt'):\n",
    "            ruta_completa = os.path.join(directorio, archivo)\n",
    "            try:\n",
    "                with open(ruta_completa, 'r', encoding='utf-8') as f:\n",
    "                    contenido = f.read()\n",
    "                    etiqueta = mapeo_etiquetas.get(archivo, 'desconocido')\n",
    "                    archivos_datos[archivo] = {\n",
    "                        'contenido': contenido,\n",
    "                        'etiqueta': etiqueta\n",
    "                    }\n",
    "                print(f\" Archivo leído: {archivo} -> Etiqueta: {etiqueta}\")\n",
    "            except Exception as e:\n",
    "                print(f\"RERRO:  Error leyendo {archivo}: {e}\")\n",
    "    \n",
    "    return archivos_datos\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    \"\"\"\n",
    "    Limpieza básica del texto\n",
    "    \"\"\"\n",
    "    # Normalizar espacios en blanco\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    # Eliminar espacios al inicio y final\n",
    "    texto = texto.strip()\n",
    "    return texto\n",
    "\n",
    "def contar_palabras(texto):\n",
    "    \"\"\"\n",
    "    Cuenta las palabras en un texto\n",
    "    \"\"\"\n",
    "    return len(texto.split())\n",
    "\n",
    "#def fragmentar_texto(texto, tam_fragmento=300, overlap=150):\n",
    "def fragmentar_texto(texto, tam_fragmento=600, overlap=300):\n",
    "    \"\"\"\n",
    "    Fragmenta el texto en chunks con overlap\n",
    "    \n",
    "    Args:\n",
    "        texto: texto a fragmentar\n",
    "        tam_fragmento: número de palabras por fragmento\n",
    "        overlap: número de palabras de solapamiento\n",
    "    \n",
    "    Returns:\n",
    "        lista de fragmentos\n",
    "    \"\"\"\n",
    "    palabras = texto.split()\n",
    "    fragmentos = []\n",
    "    \n",
    "    avance = tam_fragmento - overlap  # palabras nuevas en cada paso\n",
    "    \n",
    "    for i in range(0, len(palabras), avance):\n",
    "        fragmento_palabras = palabras[i:i + tam_fragmento]\n",
    "        \n",
    "        # Solo agregar si tiene al menos un mínimo de palabras\n",
    "        if len(fragmento_palabras) >= 50:  # mínimo 50 palabras por fragmento\n",
    "            fragmento_texto = ' '.join(fragmento_palabras)\n",
    "            fragmentos.append({\n",
    "                'texto': fragmento_texto,\n",
    "                'num_palabras': len(fragmento_palabras),\n",
    "                'posicion_inicio': i,\n",
    "                'posicion_fin': i + len(fragmento_palabras)\n",
    "            })\n",
    "        \n",
    "        # Si el último fragmento no llega al tamaño mínimo, parar\n",
    "        if i + tam_fragmento >= len(palabras):\n",
    "            break\n",
    "    \n",
    "    return fragmentos\n",
    "\n",
    "def crear_dataset(directorio_input=\"./DataSet/Lote-txt\", archivo_output=\"./DataSet/dataset_nlp.csv\"):\n",
    "    \"\"\"\n",
    "    Función principal para crear el dataset\n",
    "    \"\"\"\n",
    "    print(\" Iniciando creación del dataset...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Carga de archivos\n",
    "    print(\"Paso 1: Cargando archivos...\")\n",
    "    archivos_datos = leer_archivos_txt(directorio_input)\n",
    "    \n",
    "    if not archivos_datos:\n",
    "        print(\"ERRO: No se encontraron archivos .txt en el directorio\")\n",
    "        return None\n",
    "    \n",
    "    print(f\" Se cargaron {len(archivos_datos)} archivos\")\n",
    "    print()\n",
    "    \n",
    "    # 2. Fragmentación\n",
    "    print(\"Paso 2: Fragmentando textos...\")\n",
    "    dataset_rows = []\n",
    "    \n",
    "    for nombre_archivo, datos in archivos_datos.items():\n",
    "        print(f\"Procesando: {nombre_archivo}\")\n",
    "        \n",
    "        texto_limpio = limpiar_texto(datos['contenido'])\n",
    "        palabras_totales = contar_palabras(texto_limpio)\n",
    "        \n",
    "        #fragmentos = fragmentar_texto(texto_limpio, tam_fragmento=300, overlap=150)\n",
    "        fragmentos = fragmentar_texto(texto_limpio, tam_fragmento=600, overlap=300)\n",
    "        \n",
    "        print(f\"   Texto original: {palabras_totales} palabras\")\n",
    "        print(f\"   Fragmentos generados: {len(fragmentos)}\")\n",
    "        \n",
    "        # Agregar cada fragmento al dataset\n",
    "        for idx, fragmento in enumerate(fragmentos):\n",
    "            dataset_rows.append({\n",
    "                'texto': fragmento['texto'],\n",
    "                'etiqueta': datos['etiqueta'],\n",
    "                'archivo_origen': nombre_archivo,\n",
    "                'fragmento_id': idx + 1,\n",
    "                'num_palabras': fragmento['num_palabras'],\n",
    "                'posicion_inicio': fragmento['posicion_inicio'],\n",
    "                'posicion_fin': fragmento['posicion_fin']\n",
    "            })\n",
    "\n",
    "    \n",
    "    # 3. Crear DataFrame\n",
    "    print(f\"\\n  Paso 3: Creando DataFrame...\")\n",
    "    # texto,etiqueta,archivo_origen,fragmento_id,num_palabras,posicion_inicio,posicion_fin\n",
    "    df = pd.DataFrame(dataset_rows)\n",
    "    # nota de conceptos \n",
    "    # --- Cada fragmento es tratado como un \"documento\" independiente\n",
    "    # --- Cada fragmento tiene su propia etiqueta y características\n",
    "    print(f'       Dataset creado con {len(df)} fragmentos - {len(df)} \"documentos\" para el modelo')\n",
    "    print(f\"Estrutura -> texto,etiqueta,archivo_origen,fragmento_id,num_palabras,posicion_inicio,posicion_fin\")\n",
    "    \n",
    "    # 4. Guardar\n",
    "    print(\"  Paso 4: Guardando dataset...\")\n",
    "    \n",
    "    # Crear directorio si no existe\n",
    "    directorio_output = os.path.dirname(archivo_output)\n",
    "    if directorio_output and not os.path.exists(directorio_output):\n",
    "        os.makedirs(directorio_output)\n",
    "    \n",
    "    df.to_csv(archivo_output, index=False, encoding='utf-8')\n",
    "    print(f\"   Dataset guardado en: {archivo_output}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# ++++++++++++++++++ Descomentar si no se tiene el dataset para este ejercicio\n",
    "# llamada a la función principal para la creación del dataset \n",
    "#dataset = crear_dataset()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c95d03",
   "metadata": {},
   "source": [
    "### Carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04009402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Es un DataFrame de pandas \n",
    "Tiene columnas con nombres:\n",
    "-  'texto' (equivale a .data)\n",
    "-  'etiqueta' (equivale a .target pero con strings)\n",
    "-  No tiene equivalente directo a .target_names\n",
    "- Estructura de \"tabla con columnas\" .. NO  Estructura de \"objeto con atributos\" dataset de sklearn\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "#cargamos del datafame  panda\n",
    "#archivo_csv=\"./DataSet/dataset_nlp300.csv\" # tam_fragmento=300, overlap=150)\n",
    "archivo_csv=\"./DataSet/dataset_nlp.csv\" # tam_fragmento=600, overlap=300)\n",
    "df = pd.read_csv(archivo_csv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f6ccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info  del dataset... \n",
      "\n",
      " Distribución por clases:\n",
      "  lobo_espacial: 343 fragmentos (43.6%)\n",
      "  neuromante: 311 fragmentos (39.6%)\n",
      "  don_quijote: 99 fragmentos (12.6%)\n",
      "  deepfake: 19 fragmentos (2.4%)\n",
      "  ia_articulo: 14 fragmentos (1.8%)\n",
      "\n",
      " Estadísticas de longitud (palabras):\n",
      " - Promedio: 598.9 palabras\n",
      " - Mediana: 600.0 palabras\n",
      " - Mínimo: 310 palabras\n",
      " - Máximo: 600 palabras\n",
      "\n",
      "Fragmentos por archivo origen:\n",
      "  texto-1.txt: 343 fragmentos(documentos)\n",
      "  texto-5.txt: 311 fragmentos(documentos)\n",
      "  texto-3.txt: 99 fragmentos(documentos)\n",
      "  texto-2.txt: 19 fragmentos(documentos)\n",
      "  texto-4.txt: 14 fragmentos(documentos)\n",
      "\n",
      "Muestra del dataset (primeros 3 fragmentos):\n",
      "     etiqueta archivo_origen  fragmento_id  num_palabras\n",
      "lobo_espacial    texto-1.txt             1           600\n",
      "lobo_espacial    texto-1.txt             2           600\n",
      "lobo_espacial    texto-1.txt             3           600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Info Complementaria ------------------------\n",
    "\n",
    "# Funcipon de estadisticas \n",
    "def mostrar_estadisticas(df):\n",
    "    \"\"\"\n",
    "    Muestra estadísticas descriptivas del dataset\n",
    "    \"\"\"   \n",
    "    # Distribución por clases\n",
    "    print(\" Distribución por clases:\")\n",
    "    distribucion = df['etiqueta'].value_counts()\n",
    "    for etiqueta, cantidad in distribucion.items():\n",
    "        porcentaje = (cantidad / len(df)) * 100\n",
    "        print(f\"  {etiqueta}: {cantidad} fragmentos ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Estadísticas de longitud\n",
    "    print(\" Estadísticas de longitud (palabras):\")\n",
    "    print(f\" - Promedio: {df['num_palabras'].mean():.1f} palabras\")\n",
    "    print(f\" - Mediana: {df['num_palabras'].median():.1f} palabras\")\n",
    "    print(f\" - Mínimo: {df['num_palabras'].min()} palabras\")\n",
    "    print(f\" - Máximo: {df['num_palabras'].max()} palabras\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Distribución por archivo origen\n",
    "    print(\"Fragmentos por archivo origen:\")\n",
    "    por_archivo = df['archivo_origen'].value_counts()\n",
    "    for archivo, cantidad in por_archivo.items():\n",
    "        print(f\"  {archivo}: {cantidad} fragmentos(documentos)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Muestra del dataset\n",
    "    print(\"Muestra del dataset (primeros 3 fragmentos):\")\n",
    "    print(df[['etiqueta', 'archivo_origen', 'fragmento_id', 'num_palabras']].head(3).to_string(index=False))\n",
    "    print()\n",
    "\n",
    "#  Estadísticas\n",
    "print(f\"Info  del dataset... \\n\")\n",
    "mostrar_estadisticas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f942ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trexto fragmento 3 : de ser tan potentes como aquéllos, pero pese a todas las cosas no parecían estar tan mal. A decir verdad estaba disfrutando con aquella situación. Después de un mes de meditación en su celda de El Colmillo y de una semana encerrado a bordo de uno de los grandes cruceros estelares del Imperio en ruta hacia esta guerra menor, estaba ansioso por entrar en acción. En realidad, no era nada sorprendente porque había nacido para ello, y había sido entrenado con esa finalidad. Toda su vida había sido una preparación para este momento. Después de todo, era un Marine Espacial Imperial del Capítulo de los Lobos Espaciales. ¿Qué otra cosa podría pedirle a la vida sino esto? Tenía un bólter cargado en sus manos y, ante sí, a los enemigos del Emperador. En esta vida no había mayor placer que cumplir con el deber y acabar con la vida de aquellos lamentables herejes. La pared de ladrillos que tenía a su espalda se estremecía. Trozos de piedra golpearon su armadura, lo que le hizo pensar que alguien había alcanzado su refugio con algo pesado, tal vez un cohete o un proyectil bólter de gran calibre. No es que importara mucho, porque sabía por experiencia que el hormigón reforzado con hierro podía soportarlo. Estudió la lectura del cronómetro sobreimpresa en su campo de visión y se dio cuenta de que había pasado un minuto y cuatro segundos desde que había cursado las órdenes al hermano Hrolf. Calculaba que a Hrolf le llevaría dos minutos llegar a la posición, y otros diez segundos preparar el disparo. Era tiempo más que suficiente para que el resto de sus fuerzas se colocasen en posición. En ese tiempo, era imposible que los herejes desbaratasen su refugio a menos que contasen con mucha más potencia de fuego que la que usaban habitualmente. Aparentemente era una idea que también se le había ocurrido al comandante enemigo. Ragnar podía oír cómo se acercaba cada vez más el sonido de las monstruosas orugas. Sabía que debían pertenecer a un vehículo enemigo. Las fuerzas imperiales acababan de iniciar su descenso de la órbita con los Lobos Espaciales como punta de lanza. Era demasiado pronto para que algún blindado imperial aterrizase. La conclusión lógica era sencilla: cualquiera que se acercase no venía en son de paz. Una llamada del microrreceptor se lo confirmó enseguida. —Fuerza Ragnar. Tanque Predator enemigo acercándose a su posición. ¿Necesita ayuda? Corto. Ragnar se quedó pensativo un instante. En ese momento, la cobertura aérea de las Thunderhawk era más necesaria en otra parte, para apoyar a las tropas que se encontraban todavía en la etapa crítica del aterrizaje bajo el fuego del enemigo. No quería restarles ayuda a estos hermanos de batalla, especialmente para encargarse de un simple tanque enemigo. —Aquí Ragnar. Negativo. Nos ocuparemos del Predator nosotros mismos. Corto. —Mensaje recibido y entendido. El Emperador vela por vosotros. Corto. Ragnar sopesó sus posibilidades. Podía oír el avance del tanque, oler los humos acres de su tubo de escape. El hormigón crujía bajo sus ruedas cuando aquél se movía. Tenía la opción de pedir al hermano Hrolf que abatiese al tanque con la potente arma de apoyo del escuadrón, pero eso podría significar la cancelación del ataque contra el búnker mientras Hrolf se movía a una nueva posición, y Ragnar dudaba que fuese necesario hacerlo, sobre todo cuando él solo podía encargarse del tanque. Revisó los compartimentos de su cinturón y comprobó que todo estaba en su lugar. Jeringuillas para medicamentos cicatrizantes, dispensadores de granadas, parches de reparación. Golpeó el dispensador de granadas y cayó una granada \n",
      "\n",
      " etiqueta / clases : ['lobo_espacial' 'deepfake' 'don_quijote' 'ia_articulo' 'neuromante'] \n",
      "\n",
      "documentos hay por clase:  etiqueta\n",
      "lobo_espacial    343\n",
      "neuromante       311\n",
      "don_quijote       99\n",
      "deepfake          19\n",
      "ia_articulo       14\n",
      "Name: count, dtype: int64  \n",
      "\n",
      " texto              de ser tan potentes como aquéllos, pero pese a...\n",
      "etiqueta                                               lobo_espacial\n",
      "archivo_origen                                           texto-1.txt\n",
      "fragmento_id                                                       3\n",
      "num_palabras                                                     600\n",
      "posicion_inicio                                                  600\n",
      "posicion_fin                                                    1200\n",
      "Name: 2, dtype: object \n",
      "\n",
      "\n",
      " primer texto de cada clase :\n",
      "Clase lobo_espacial: William King Lobo espacial Warhammer 40000. Lobos espaciales 1 ePub r1.2 epublector 20.06.13 Título ...\n",
      "Clase deepfake: Deepfake: Todo lo que necesitas saber al respecto Andrey 8 de diciembre de 2020 Hoy en día, la tecno...\n",
      "Clase don_quijote: ¿Es una locura dejarse llevar por el sentimiento? Esto es lo que hizo don Quijote: guiado por el amo...\n",
      "Clase ia_articulo: ¿Qué es la inteligencia artificial (IA)? Inteligencia Artificial IA en Mendoza La Inteligencia Artif...\n",
      "Clase neuromante: Case era el mejor vaquero del ciberespacio: se ganaba la vida robando información y traspasando defe...\n"
     ]
    }
   ],
   "source": [
    "# fragmento de texto. \n",
    "Texto = df['texto'].iloc[2]\n",
    "print(f\" Trexto fragmento 3 : {Texto} \\n\")\n",
    "\n",
    "## etiqueta numero 5 \n",
    "#etiqueta_doc = df['etiqueta'].iloc[5]\n",
    "#print(f' etiqueta / clases : {etiqueta_doc} \\n')\n",
    "\n",
    "## Ver todas las clases/ etiquetas  \n",
    "clases = df['etiqueta'].unique()\n",
    "print(f' etiqueta / clases : {clases} \\n')\n",
    "\n",
    "# cuántos documentos hay por clase\n",
    "distribucion_clases = df['etiqueta'].value_counts()\n",
    "print(f'documentos hay por clase:  {distribucion_clases}  \\n')\n",
    "\n",
    "# 5. Ver información completa del fragmento \n",
    "info_doc5 = df.iloc[2]\n",
    "print(f' {info_doc5} \\n')\n",
    "\n",
    "## 6. Ver todos los documentos de una clase específica\n",
    "#docs_don_quijote = df[df['etiqueta'] == 'don_quijote']\n",
    "#print(f\"\\n Documentos de Don Quijote: {len(docs_don_quijote)} \\n\")\n",
    "\n",
    "# 7. Ver primer texto de cada clase\n",
    "print (f'\\n primer texto de cada clase :')\n",
    "for clase in df['etiqueta'].unique():\n",
    "    primer_texto = df[df['etiqueta'] == clase]['texto'].iloc[0]\n",
    "    print(f\"Clase {clase}: {primer_texto[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506ce4c",
   "metadata": {},
   "source": [
    "<h3><a href=\"#1\">Punto 1</a></h3>\n",
    "\n",
    "- Vectorizar documentos. \n",
    "- medir similaridad con el resto de los documentos\n",
    "    - Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5493a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizamos el 100% de los datos del DataFrame para entrenamiento y testing  \n",
    "df_train = df\n",
    "df_test = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d81a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "tfidfvect = TfidfVectorizer()\n",
    "X_train = tfidfvect.fit_transform(df_train['texto']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5bde08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "shape: (786, 20713) documentos, términos\n",
      "Cantidad de documentos: 786\n",
      "Tamaño del vocabulario (dimensionalidad de los vectores): 20713 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(X_train))\n",
    "print(f'shape: {X_train.shape} documentos, términos')\n",
    "print(f'Cantidad de documentos: {X_train.shape[0]}')\n",
    "print(f'Tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda962d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 20526)\t0.10283491815316567\n",
      "  (0, 11575)\t0.11838698006512331\n",
      "  (0, 12083)\t0.023018584485384623\n",
      "  (0, 8201)\t0.0304721218691385\n",
      "  (0, 20517)\t0.059193490032561656\n",
      "  (0, 86)\t0.059193490032561656\n",
      "  (0, 12084)\t0.02495721654982468\n",
      "  (0, 8202)\t0.029781788344500487\n",
      "  (0, 7932)\t0.10662229938989885\n",
      "  (0, 16197)\t0.10662229938989885\n",
      "  (0, 7933)\t0.11838698006512331\n",
      "  (0, 49)\t0.042094170224988015\n",
      "  (0, 11)\t0.046429252666984264\n",
      "  (0, 20)\t0.0455351187389706\n",
      "  (0, 19777)\t0.044726276214652534\n",
      "  (0, 14109)\t0.04103198282059592\n",
      "  (0, 18477)\t0.059193490032561656\n",
      "  (0, 20531)\t0.059193490032561656\n",
      "  (0, 48)\t0.059193490032561656\n",
      "  (0, 19416)\t0.051417459076582836\n",
      "  (0, 7262)\t0.059193490032561656\n",
      "  (0, 13375)\t0.059193490032561656\n",
      "  (0, 52)\t0.059193490032561656\n",
      "  (0, 7093)\t0.046429252666984264\n",
      "  (0, 6591)\t0.0455351187389706\n",
      "  :\t:\n",
      "  (785, 17282)\t0.04350315192820584\n",
      "  (785, 16677)\t0.08020703154216098\n",
      "  (785, 9111)\t0.07103106163867219\n",
      "  (785, 18951)\t0.07242583744936117\n",
      "  (785, 19081)\t0.0640065378459706\n",
      "  (785, 969)\t0.08020703154216098\n",
      "  (785, 12313)\t0.07242583744936117\n",
      "  (785, 18015)\t0.19699039001215596\n",
      "  (785, 9969)\t0.07575276958570079\n",
      "  (785, 4364)\t0.08020703154216098\n",
      "  (785, 19520)\t0.08696940565413681\n",
      "  (785, 11244)\t0.08696940565413681\n",
      "  (785, 45)\t0.08696940565413681\n",
      "  (785, 1476)\t0.08696940565413681\n",
      "  (785, 1010)\t0.08696940565413681\n",
      "  (785, 3608)\t0.08696940565413681\n",
      "  (785, 5719)\t0.08696940565413681\n",
      "  (785, 19232)\t0.08696940565413681\n",
      "  (785, 9543)\t0.08696940565413681\n",
      "  (785, 9120)\t0.08696940565413681\n",
      "  (785, 14447)\t0.08696940565413681\n",
      "  (785, 12882)\t0.08696940565413681\n",
      "  (785, 13834)\t0.08696940565413681\n",
      "  (785, 9729)\t0.08696940565413681\n",
      "  (785, 46)\t0.09233700395542369\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "042be016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La palabra espacio esta en la posición --   8203 -- del vector \n"
     ]
    }
   ],
   "source": [
    "print(f\" La palabra espacio esta en la posición --   {tfidfvect.vocabulary_['espacio']} -- del vector \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3be69f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALgunas palabras y su indice : {20526: 'william', 11575: 'king', 12083: 'lobo', 8201: 'espacial', 20517: 'warhammer', 86: '40000', 12084: 'lobos', 8202: 'espaciales', 7932: 'epub', 16197: 'r1'}\n"
     ]
    }
   ],
   "source": [
    "# crea un diccionario inverso que mapea índices a palabras de manera Inversa  índices de las palabras de vuelta a texto\n",
    "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()} \n",
    "algunas_palabras = dict(list(idx2word.items())[:10])\n",
    "print(f'ALgunas palabras y su indice : {algunas_palabras}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b698b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 20713 palabras\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamaño del vocabulario: {len(tfidfvect.vocabulary_)} palabras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c167a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicas 10 de algunas palabras : ['william', 'king', 'lobo', 'espacial', 'warhammer', '40000', 'lobos', 'espaciales', 'epub', 'r1']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Indicas 10 de algunas palabras : {list(tfidfvect.vocabulary_.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "989bce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lobo_espacial:\n",
      "   Rango: del idx de los fragmentos 0 al 342\n",
      "   Cantidad: 343 documentos\n",
      " deepfake:\n",
      "   Rango: del idx de los fragmentos 343 al 361\n",
      "   Cantidad: 19 documentos\n",
      " don_quijote:\n",
      "   Rango: del idx de los fragmentos 362 al 460\n",
      "   Cantidad: 99 documentos\n",
      " ia_articulo:\n",
      "   Rango: del idx de los fragmentos 461 al 474\n",
      "   Cantidad: 14 documentos\n",
      " neuromante:\n",
      "   Rango: del idx de los fragmentos 475 al 785\n",
      "   Cantidad: 311 documentos\n"
     ]
    }
   ],
   "source": [
    "def analizar_indices_por_clase(df):\n",
    "    \"\"\"\n",
    "    indica el rango de los indice `idx` de los documentos (fragmentos) de cada etiqueta\n",
    "    \"\"\"\n",
    "    \n",
    "    clases_ordenadas = df['etiqueta'].unique()  # Orden de aparición en el dataset\n",
    "    \n",
    "    for clase in clases_ordenadas:\n",
    "        # Obtener todos los índices de esa clase\n",
    "        indices_clase = df[df['etiqueta'] == clase].index.tolist()\n",
    "        \n",
    "        min_idx = min(indices_clase)\n",
    "        max_idx = max(indices_clase)\n",
    "        cantidad = len(indices_clase)\n",
    "        \n",
    "        print(f\" {clase}:\")\n",
    "        print(f\"   Rango: del idx de los fragmentos {min_idx} al {max_idx}\")\n",
    "        print(f\"   Cantidad: {cantidad} documentos\")\n",
    "\n",
    "analizar_indices_por_clase(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00270519",
   "metadata": {},
   "source": [
    "### Similitud Coseno `cosine_similarity`\n",
    "\n",
    "\n",
    "**La Similitud Coseno** es una métrica fundamental en el Procesamiento del Lenguaje Natural (PLN) que se utiliza para medir cuán similares son dos documentos de texto. No mide la magnitud de los vectores, sino la orientación de sus vectores. Imagina cada documento como un vector en un espacio multidimensional; la similitud coseno _calcula el coseno del ángulo_ entre estos dos vectores. \n",
    "\n",
    "La idea central es que, si dos documentos que tratan sobre temas similares, es probable que utilicen un vocabulario similar, lo que resultaría en vectores que apuntan en direcciones parecidas en el espacio vectorial. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f0d0f",
   "metadata": {},
   "source": [
    "En en siguiente ejercicio estamos realizando la Similitud de Coseno en el fragmento 10 `idx= 10` contra todos los fragmentos (documentos) de los 5 artículos que contienen distinta información entre los mismos, pero dentro de los fragmentos correspondiente a dichos artículos observamos un valor en la la similaridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55909946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Etiquetas / Clases:   lobo_espacial \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'en aquella extraña sensación. Sabía lo que podía esperar o debía saberlo: al fin y al cabo había muerto anteriormente. Una helada claridad se apoderó de su espíritu, y su memoria se remontó en el pasado mientras su alma se aventuraba siglos atrás, recordando. UNO EL ÚLTIMO BALUARTE —¡Vamos a morir todos! —gritó Yorvik el Arponero, alumbrando en derredor y con los ojos muy abiertos por el miedo. Un relámpago cruzó el cielo de Fenris e iluminó la cara atormentada del hombre. El profundo terror hizo que su alarido se oyese, incluso, por encima del rugido del viento y del ruido atronador de las olas que chocaban contra el barco. Las gotas de la lluvia que azotaba su rostro resbalaban como lágrimas. —¡Quédate callado! —contestó Ragnar mientras abofeteaba la cara del aterrorizado hombre. Estupefacto por haber sido golpeado por un jovencito que apenas tenía edad para lucir barba en las mejillas, Yorvik echó mano de su hacha, olvidado momentáneamente de su miedo. Ragnar movió la cabeza y clavó su fría mirada gris en el hombre, que se detuvo súbitamente como si tomara conciencia de dónde estaba y de lo que estaba haciendo. Quedaron a la vista de todos los guerreros que llenaban la proa del barco. Atacar al hijo de su capitán podría desacreditarlo a los ojos de los dioses o de la tripulación. La sangre arreboló las mejillas de Yorvik, y Ragnar desvió la mirada para no poner más incómodo al hombre. Ragnar sacudió la cabeza para apartar su larga melena negra de los ojos. Entrecerrando los ojos por el azote del viento y de la lluvia de agua salada que levantaba el mar embravecido, compartió silenciosamente el miedo de Yorvik. Iban a morir a menos que ocurriera un milagro. Se había aventurado en el mar desde que tuvo edad suficiente para caminar y nunca había visto una tormenta tan terrible. El cielo estaba cerrado de espesas nubes negras que habían convertido el día en noche. El agua entró a borbotones por la proa cuando el barco se adentró en otra gigantesca ola y la piel de dragón del casco sonó como un enorme tambor por la fuerza del impacto. Ragnar luchó para mantener el equilibrio sobre el puente en permanente movimiento. Podía oír el crujido de las costillas del barco por encima de los alaridos del endemoniado viento. Era sólo cuestión de tiempo, pero aceptó que el mar acabaría matando al barco. Estaban en una carrera para ver si la fuerza de las olas deshacía al Lanza de Russ en mil pedazos, o si únicamente arrancaba la piel del dragón del esqueleto y dejaba que todos se ahogasen. Ragnar temblaba y no precisamente por el frío húmedo de sus ropas empapadas. Para él, y para su gente, ahogarse era la peor de las muertes posibles porque significaba simplemente hundirse en las garras de los demonios del mar, en las que sus almas quedarían condenados a una eternidad de esclavitud. Ya no habría posibilidad de ganarse un lugar entre los Elegidos. No moriría con la espada ni con el hacha en la mano, ni encontraría una muerte gloriosa ni un rápido tránsito a la Sala de los Héroes de las Montañas de los Dioses. Mirando hacia atrás a lo largo de la cubierta azotada por la lluvia, Ragnar vio que todos los imponentes guerreros estaban tan atemorizados como él, pero ellos lo ocultaban muy bien. La tensión estaba escrita en cada pálido rostro, y asomaba a los ojos azules de todos. La lluvia empapaba sus largos cabellos rubios y les daba un aspecto desesperanzado. Estaban sentados en sus bancos'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definimos Fragmento \n",
    "idx= 10\n",
    "# vemos a que Etiqueta corresponde \n",
    "print (f' Etiquetas / Clases:   {df_train['etiqueta'].iloc[idx]} \\n')\n",
    "# Vemos el Texto almacenado en el fragmento \n",
    "df_train['texto'].iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c963be62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Calcular Similaridad coseno entre el fragmento --10-- que pertenece a la Etiquetas/Clases: --lobo_espacial-- con todos los documentos (fragmentos )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.72787623, 0.71415594, 0.47912957, 0.4603731 ,\n",
       "       0.4563406 , 0.45330197, 0.44571104, 0.43744339, 0.43196383,\n",
       "       0.42254724, 0.41899589, 0.41705214, 0.41675146, 0.41377503,\n",
       "       0.41236456, 0.41220132, 0.41211592, 0.41130716, 0.40811557,\n",
       "       0.40734294, 0.40633294, 0.40591669, 0.40475013, 0.40405163,\n",
       "       0.40351019, 0.40271437, 0.40253351, 0.40248306, 0.40150139,\n",
       "       0.39982681, 0.39962146, 0.39958535, 0.39943688, 0.3988447 ,\n",
       "       0.39854427, 0.39649409, 0.39630514, 0.39624484, 0.39611708,\n",
       "       0.39592964, 0.39583402, 0.3946352 , 0.39424896, 0.39423572,\n",
       "       0.39414219, 0.3935196 , 0.39316394, 0.39251415, 0.39226937,\n",
       "       0.39212065, 0.39158939, 0.38956175, 0.38924259, 0.38888524,\n",
       "       0.38874781, 0.38834659, 0.38810721, 0.38808609, 0.38806783,\n",
       "       0.38784481, 0.38780766, 0.38769816, 0.38758601, 0.38738744,\n",
       "       0.38705703, 0.38697786, 0.38644617, 0.3863802 , 0.38618373,\n",
       "       0.38582311, 0.38555636, 0.38536979, 0.38472787, 0.38418281,\n",
       "       0.38396893, 0.38377885, 0.38361698, 0.38325419, 0.38319946,\n",
       "       0.38279967, 0.38231335, 0.38226225, 0.38215383, 0.38203023,\n",
       "       0.38199464, 0.38186595, 0.38170929, 0.38136224, 0.38096305,\n",
       "       0.38092866, 0.3803661 , 0.38022936, 0.38018356, 0.37991641,\n",
       "       0.37969069, 0.37951002, 0.37863581, 0.37810003, 0.37806697,\n",
       "       0.3779625 , 0.37724693, 0.37690704, 0.37658655, 0.37648319,\n",
       "       0.37638011, 0.37616641, 0.37595883, 0.37570633, 0.3751438 ,\n",
       "       0.37513841, 0.37487066, 0.37463337, 0.37461957, 0.37442349,\n",
       "       0.37432839, 0.37379399, 0.37372144, 0.37358707, 0.37339553,\n",
       "       0.373289  , 0.37328616, 0.37324972, 0.37323978, 0.37281546,\n",
       "       0.37256662, 0.37245385, 0.37236187, 0.37204774, 0.3720294 ,\n",
       "       0.37194483, 0.37189591, 0.37164301, 0.37163944, 0.37143095,\n",
       "       0.37127628, 0.37124022, 0.37088527, 0.3701231 , 0.3699242 ,\n",
       "       0.36957798, 0.36952722, 0.36864323, 0.36852706, 0.36846875,\n",
       "       0.36807488, 0.36764205, 0.36753735, 0.36746738, 0.36743878,\n",
       "       0.36743369, 0.36718271, 0.36702323, 0.36700083, 0.36662078,\n",
       "       0.36655935, 0.36632582, 0.36629808, 0.36603941, 0.36600034,\n",
       "       0.36595129, 0.36594608, 0.36591073, 0.36537695, 0.3653702 ,\n",
       "       0.36527406, 0.36518235, 0.36485895, 0.36473783, 0.36450833,\n",
       "       0.36437576, 0.36434339, 0.3641957 , 0.36411833, 0.36407977,\n",
       "       0.36388599, 0.36383472, 0.36365129, 0.36355161, 0.36312651,\n",
       "       0.36292714, 0.3629231 , 0.3628832 , 0.36267016, 0.36253074,\n",
       "       0.3624402 , 0.36232956, 0.36212392, 0.36202406, 0.36176648,\n",
       "       0.36166245, 0.36164423, 0.36083388, 0.36075271, 0.36049762,\n",
       "       0.36048475, 0.35967759, 0.3593312 , 0.35780112, 0.35763829,\n",
       "       0.357525  , 0.35746942, 0.35726021, 0.35719954, 0.35709164,\n",
       "       0.3570758 , 0.35694691, 0.35687882, 0.35683687, 0.35675706,\n",
       "       0.35671655, 0.35608466, 0.35600145, 0.35569997, 0.35569463,\n",
       "       0.3556679 , 0.35543099, 0.35540644, 0.35535596, 0.35530414,\n",
       "       0.35517669, 0.35502024, 0.35491462, 0.35472943, 0.35471945,\n",
       "       0.35459611, 0.35441485, 0.35438758, 0.35418886, 0.35385101,\n",
       "       0.3537108 , 0.35362927, 0.35352288, 0.35351433, 0.35337398,\n",
       "       0.35316688, 0.35294264, 0.35289052, 0.35285292, 0.35278224,\n",
       "       0.3524414 , 0.3523886 , 0.35222005, 0.35176246, 0.35162626,\n",
       "       0.35122568, 0.3510833 , 0.35095852, 0.35092385, 0.35091725,\n",
       "       0.35090363, 0.35077538, 0.35063721, 0.35012996, 0.34986433,\n",
       "       0.3498622 , 0.34985322, 0.34979653, 0.34976521, 0.34974864,\n",
       "       0.34960754, 0.34928915, 0.34899966, 0.34869707, 0.34863048,\n",
       "       0.34851849, 0.34840194, 0.34832261, 0.34828014, 0.34825486,\n",
       "       0.34821484, 0.34818953, 0.34814246, 0.34802367, 0.34781257,\n",
       "       0.34765545, 0.34724069, 0.34712253, 0.34682458, 0.34682268,\n",
       "       0.34679369, 0.34677872, 0.34653714, 0.34647903, 0.34637803,\n",
       "       0.34635204, 0.34626391, 0.34601593, 0.34586748, 0.34580187,\n",
       "       0.34577319, 0.3454324 , 0.34509422, 0.34490063, 0.3448416 ,\n",
       "       0.34470078, 0.34466381, 0.34450229, 0.34436087, 0.34416884,\n",
       "       0.34409012, 0.34396054, 0.3439239 , 0.34383864, 0.34333982,\n",
       "       0.34331691, 0.34320075, 0.34295949, 0.34290308, 0.34288913,\n",
       "       0.34287061, 0.34280373, 0.34257794, 0.34256551, 0.34247603,\n",
       "       0.34232068, 0.34199054, 0.34146828, 0.34139593, 0.34110992,\n",
       "       0.34087105, 0.34086442, 0.34086316, 0.34071549, 0.34053924,\n",
       "       0.34050732, 0.34026693, 0.34016657, 0.34012676, 0.33986257,\n",
       "       0.33985987, 0.33969986, 0.33951959, 0.33920899, 0.33918098,\n",
       "       0.33913108, 0.33911222, 0.33898956, 0.33898892, 0.33897558,\n",
       "       0.33895291, 0.33886345, 0.33870184, 0.33848434, 0.3381994 ,\n",
       "       0.33818095, 0.33773669, 0.33753381, 0.33730974, 0.33716931,\n",
       "       0.33710922, 0.33668234, 0.33618554, 0.3360776 , 0.33597135,\n",
       "       0.3357583 , 0.33575106, 0.33561288, 0.33554737, 0.33554092,\n",
       "       0.33552724, 0.33529196, 0.3345766 , 0.33421005, 0.33406477,\n",
       "       0.33406289, 0.3339729 , 0.33395888, 0.33368346, 0.33366355,\n",
       "       0.3334122 , 0.33329312, 0.33291162, 0.33290885, 0.33272558,\n",
       "       0.33263008, 0.33235364, 0.33231779, 0.33213747, 0.33205233,\n",
       "       0.33189523, 0.33171762, 0.33156386, 0.33155564, 0.3311467 ,\n",
       "       0.33114083, 0.33076559, 0.33076369, 0.33043991, 0.33023872,\n",
       "       0.33015637, 0.33015538, 0.32998826, 0.32983615, 0.32950718,\n",
       "       0.32944678, 0.32917307, 0.32915173, 0.32897775, 0.3289473 ,\n",
       "       0.32886781, 0.32883311, 0.32860479, 0.32856363, 0.32852752,\n",
       "       0.32829978, 0.32816525, 0.32816328, 0.32779532, 0.32720209,\n",
       "       0.3270137 , 0.32676678, 0.32673288, 0.32662342, 0.32648683,\n",
       "       0.3264857 , 0.32648243, 0.32636094, 0.32633841, 0.32587079,\n",
       "       0.32585643, 0.32585618, 0.32585318, 0.32567464, 0.3256539 ,\n",
       "       0.32524891, 0.32516303, 0.32512064, 0.32493789, 0.32473914,\n",
       "       0.32460136, 0.32441331, 0.32440854, 0.3241339 , 0.32384122,\n",
       "       0.32383657, 0.32345819, 0.32318421, 0.32308083, 0.32295523,\n",
       "       0.32274202, 0.3224259 , 0.32200374, 0.32195322, 0.32194169,\n",
       "       0.32188039, 0.32168094, 0.3216711 , 0.3216579 , 0.32131332,\n",
       "       0.32110089, 0.32099887, 0.32075527, 0.32075088, 0.32072181,\n",
       "       0.32003241, 0.31986206, 0.31978935, 0.31972975, 0.31957657,\n",
       "       0.31956968, 0.31952785, 0.3195221 , 0.3194803 , 0.31944943,\n",
       "       0.3193717 , 0.31899464, 0.31895794, 0.3188543 , 0.31883962,\n",
       "       0.31869865, 0.31856171, 0.31836127, 0.31835883, 0.31806549,\n",
       "       0.31771248, 0.31766897, 0.31763261, 0.31739958, 0.31735492,\n",
       "       0.31728759, 0.31604396, 0.31599987, 0.315916  , 0.31580304,\n",
       "       0.31579241, 0.31575984, 0.31569379, 0.31500736, 0.31495786,\n",
       "       0.31495151, 0.31481767, 0.31471954, 0.31416898, 0.31408158,\n",
       "       0.31392016, 0.31387234, 0.31380026, 0.31377445, 0.31374909,\n",
       "       0.31326441, 0.31306102, 0.31302513, 0.31291521, 0.31237343,\n",
       "       0.31225764, 0.31207331, 0.31159438, 0.31137681, 0.31103078,\n",
       "       0.31037353, 0.31025907, 0.31025688, 0.30990488, 0.30965153,\n",
       "       0.3095407 , 0.30945601, 0.30917136, 0.30914347, 0.30911006,\n",
       "       0.30885234, 0.30878232, 0.3087247 , 0.30872045, 0.30858423,\n",
       "       0.30821309, 0.30818478, 0.30814288, 0.30793693, 0.30782148,\n",
       "       0.30779589, 0.30771227, 0.30761344, 0.30754042, 0.30750391,\n",
       "       0.30749993, 0.30742036, 0.30717773, 0.30667739, 0.30655386,\n",
       "       0.30650761, 0.30623312, 0.3060001 , 0.3053535 , 0.30523608,\n",
       "       0.30501465, 0.30489174, 0.30468145, 0.30447548, 0.30435941,\n",
       "       0.3042941 , 0.30410509, 0.30399705, 0.30370724, 0.30338412,\n",
       "       0.3031913 , 0.30285629, 0.30270357, 0.30223965, 0.3019755 ,\n",
       "       0.30184419, 0.30182696, 0.30149775, 0.30133911, 0.3009139 ,\n",
       "       0.30006437, 0.30004352, 0.29984779, 0.29933015, 0.2992969 ,\n",
       "       0.29912533, 0.29904886, 0.29894597, 0.29885908, 0.29870652,\n",
       "       0.29858833, 0.2985245 , 0.29847532, 0.29827347, 0.29824879,\n",
       "       0.29811499, 0.29755127, 0.29701805, 0.29682912, 0.29672992,\n",
       "       0.2966759 , 0.29665049, 0.29656866, 0.29654589, 0.29543271,\n",
       "       0.29510296, 0.2943995 , 0.29389357, 0.29382687, 0.29324158,\n",
       "       0.29269667, 0.29259311, 0.29255944, 0.29228045, 0.29193153,\n",
       "       0.29065156, 0.29053693, 0.29043389, 0.29008976, 0.28952439,\n",
       "       0.2892929 , 0.28902821, 0.28894604, 0.28884857, 0.28877346,\n",
       "       0.28866853, 0.28829383, 0.28787697, 0.28781432, 0.28718855,\n",
       "       0.28712086, 0.28702018, 0.28682054, 0.28623732, 0.28585904,\n",
       "       0.28584963, 0.28584595, 0.28572736, 0.2856045 , 0.28546908,\n",
       "       0.2853559 , 0.28533584, 0.28483989, 0.28472872, 0.28471478,\n",
       "       0.28345446, 0.28318328, 0.28264119, 0.28260958, 0.282546  ,\n",
       "       0.28238116, 0.28221834, 0.28174503, 0.28171189, 0.281318  ,\n",
       "       0.28091415, 0.28033876, 0.28025816, 0.28023483, 0.27977562,\n",
       "       0.27941306, 0.27940015, 0.27914834, 0.27908178, 0.27906601,\n",
       "       0.27873986, 0.27841895, 0.27809703, 0.27522639, 0.2748091 ,\n",
       "       0.27444955, 0.27438987, 0.27434509, 0.27394079, 0.27386081,\n",
       "       0.27329779, 0.27320737, 0.27258131, 0.27247596, 0.27247205,\n",
       "       0.27199106, 0.27133311, 0.27099125, 0.27027923, 0.27024658,\n",
       "       0.2702408 , 0.27010297, 0.26949272, 0.26870655, 0.26806198,\n",
       "       0.26798709, 0.26757257, 0.26751386, 0.26684648, 0.26657376,\n",
       "       0.26653661, 0.26608274, 0.26594025, 0.26561692, 0.26533146,\n",
       "       0.26520566, 0.26507713, 0.26459126, 0.26450002, 0.26401556,\n",
       "       0.26397867, 0.26365458, 0.26325076, 0.26307197, 0.26293286,\n",
       "       0.2625259 , 0.26195792, 0.26179392, 0.26144058, 0.26069801,\n",
       "       0.26044913, 0.26005196, 0.25969451, 0.25958149, 0.25953706,\n",
       "       0.2594792 , 0.25947456, 0.25938459, 0.25867608, 0.25828746,\n",
       "       0.25762353, 0.25755765, 0.25724924, 0.25678785, 0.25672018,\n",
       "       0.2559333 , 0.25563874, 0.25559834, 0.25514802, 0.25453644,\n",
       "       0.25422765, 0.25386016, 0.25261857, 0.2522745 , 0.25183752,\n",
       "       0.2511361 , 0.25102804, 0.24998298, 0.24986095, 0.24930523,\n",
       "       0.24902926, 0.24843756, 0.24717165, 0.24702404, 0.24676559,\n",
       "       0.24637402, 0.2462472 , 0.24604568, 0.24568499, 0.24566493,\n",
       "       0.2443937 , 0.2440618 , 0.24310934, 0.24296091, 0.24291563,\n",
       "       0.24290716, 0.24269155, 0.24247541, 0.24243387, 0.24198096,\n",
       "       0.24157077, 0.24106358, 0.23956994, 0.23924341, 0.23844492,\n",
       "       0.23790868, 0.23563586, 0.2353949 , 0.23495202, 0.23288672,\n",
       "       0.2321044 , 0.23200771, 0.23192422, 0.23156359, 0.23148997,\n",
       "       0.23140639, 0.22981748, 0.22887866, 0.22868467, 0.2257345 ,\n",
       "       0.22496861, 0.22423128, 0.22418154, 0.22366298, 0.22271693,\n",
       "       0.21826729, 0.21764675, 0.21745463, 0.21425153, 0.21369113,\n",
       "       0.20046572, 0.19802126, 0.18675971, 0.1797764 , 0.14861724,\n",
       "       0.14030177])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print (f' Calcular Similaridad coseno entre el fragmento --{idx}-- que pertenece a la Etiquetas/Clases: --{df_train['etiqueta'].iloc[idx]}-- con todos los documentos (fragmentos )\\n')\n",
    "## Calcular Similaridad coseno entre el fragmento idx con todos los documentos (fragmentos )\n",
    "cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
    "# Ordena los valores de similaridad de mayor a menor\n",
    "np.sort(cossim)[::-1] # todos documentos \n",
    "\n",
    "# Vemos  cuáles son los valores de similaridad más altos NO indica qué documentos tienen esos vectores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fa913",
   "metadata": {},
   "source": [
    "como podemos observar en los resultados obtenidos en la _Similaridad entre el fragmento 10 contra todos los fragmentos_.\n",
    "- EL valor 1.0: como la **similaridad  perfecta** asumimos que estamos analizando el mismo fragmento 10 contra si mismo\n",
    "- Podemos asumir que los rangos entre 0.7 y 0.4 son los documentos que pertenecen al documento _lobo_espacial_\n",
    "- El resto de valores enter 0.3 y 0.1 que tienen un valor de similaridad muy baja podemos asumir que pertenecen al resto de los documentos. \n",
    "\n",
    "En los siguientes códigos mostramos otros códigos para mostrar los valores asignados a los fragmentos, similitud e identificación de los mismos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "603fbdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,   9,  11,  14,  15,  13,  16,  12,  17,  76,  69,  38,  35,\n",
       "        46,  45,  22, 243,  54,  89, 317,  88,  52, 158, 105,  53,  70,\n",
       "        79,  57, 244, 280,  66, 486, 159,  60,  68,  21,  75,  39,  41,\n",
       "       221, 237, 236,  64, 337, 230, 268,  34,  58, 124, 213,  67,  86,\n",
       "       272, 162,  37, 153,  72,  49, 316, 127,  80,  29, 269, 233,  73,\n",
       "       315,  65, 209, 290,  77, 163, 239, 180,  87,  51, 176,   7,   8,\n",
       "       185, 304, 175, 131, 487,  63, 208,  25,  18, 314, 302,  61, 242,\n",
       "       279, 657, 128,  59, 291, 303, 186, 311, 324, 222, 245, 501,  36,\n",
       "        24, 281, 179, 748, 223, 238, 774,  92, 220,  26,  48, 267, 313,\n",
       "       318, 273, 106,  32, 295,  85, 140, 301,  44, 294,  40, 338, 500,\n",
       "       207, 541, 161, 130, 169, 312, 232, 143, 725, 104,  28, 134, 212,\n",
       "       157, 231, 139,  91, 747,  47, 559, 166, 658, 256, 202, 154, 775,\n",
       "       227, 693, 210, 164, 310,  55, 206, 150, 326, 260, 203, 694, 192,\n",
       "       178,  20,  23,  71,  84, 229, 339, 327,  43, 146,  27, 172, 103,\n",
       "       247,   6, 133, 724, 170, 193,  62, 171, 711, 165,  19, 226, 328,\n",
       "       234, 118, 252, 235, 108, 160, 321, 289, 114, 558, 132,  56,  78,\n",
       "       271, 181, 107, 177, 325, 323, 240, 780,  42, 336, 757, 144, 173,\n",
       "       656, 274, 115, 710, 296, 123, 712, 282, 525, 191, 550, 102, 219,\n",
       "       621,   5, 183, 527, 121, 261,  31, 285, 156,   1, 744, 753, 288,\n",
       "       320, 305, 259,  90, 152, 214, 614,  83, 540, 155, 526, 287, 184,\n",
       "       270, 544, 120,  50, 251,  74, 721, 762, 319, 688, 248, 168, 100,\n",
       "       453, 292, 286, 485, 293, 190, 535, 488, 167, 726, 297,  95, 225,\n",
       "       174, 720, 580, 149, 224, 676, 211, 685, 620, 553, 517, 749, 142,\n",
       "       489, 722, 125, 194, 684, 228, 126, 551, 499, 101, 278, 528, 784,\n",
       "       218, 745, 332, 773, 587, 659, 298, 284, 689, 692, 652, 695, 257,\n",
       "       677, 529, 543, 524, 777,  99, 216, 306, 723, 198, 781,  81, 484,\n",
       "       612, 196, 145, 283, 772, 217, 266, 719, 129, 554, 199, 542,   4,\n",
       "        94, 195, 340, 707, 686, 502, 534, 530, 783, 547, 135, 737, 735,\n",
       "       563, 713, 736,  33,  30, 571,   0, 204, 113, 483, 683, 454, 746,\n",
       "       619, 516, 596, 275, 333, 717, 205, 623, 782, 334, 611, 335, 613,\n",
       "       675, 307, 770, 622, 549, 189, 776, 778, 277, 197, 265, 299,  97,\n",
       "       117, 678, 750, 182, 504, 322, 546, 141, 545, 769, 110, 556, 586,\n",
       "       734, 119, 641, 478, 642, 109, 771, 518, 246, 533, 503, 701, 552,\n",
       "       557, 779, 548, 241, 555, 264, 581, 300, 331,  96, 479, 665, 138,\n",
       "       509, 700, 637, 147, 151, 255, 583, 681, 624, 638, 752, 758, 761,\n",
       "       705, 597, 696, 664, 765, 653, 116, 760, 564, 718, 687, 714, 329,\n",
       "       490, 496, 662, 647, 682, 477, 482, 608, 756, 562, 579, 706, 508,\n",
       "       754, 187, 111, 201, 372, 578,  98, 727, 122, 594, 476, 733, 763,\n",
       "       640,  93, 708, 639, 475, 766, 497, 422, 588, 515, 743, 679, 741,\n",
       "       759, 740, 698,   2, 618, 258, 495, 730, 651, 148, 739, 250, 263,\n",
       "       631, 309, 699, 697, 200, 262,  82, 519, 403, 253, 666, 523, 215,\n",
       "       615, 498, 572, 308, 137, 709, 785, 536, 593, 595, 605, 254, 468,\n",
       "       570, 716, 702, 625, 112, 249, 560, 276, 655, 646, 729, 575, 481,\n",
       "       680, 598, 663, 633, 532, 136, 455, 599, 715, 577, 421, 738, 636,\n",
       "       469, 634, 584, 188, 654, 751, 510, 365,   3, 456, 632, 505, 574,\n",
       "       690, 341, 492, 742, 626, 607, 767, 582, 373, 400, 643, 671, 585,\n",
       "       672, 732, 330, 728, 531, 381, 431, 511, 704, 399, 674, 768, 494,\n",
       "       380, 491, 561, 371, 539, 589, 691, 635, 467, 606, 514, 576, 764,\n",
       "       480, 493, 473, 648, 667, 565, 627, 387, 731, 457, 600, 430, 661,\n",
       "       472, 609, 395, 644, 463, 362, 452, 669, 668, 755, 384, 368, 573,\n",
       "       385, 366, 512, 462, 382, 394, 459, 660, 379, 520, 389, 446, 474,\n",
       "       386, 522, 603, 415, 374, 703, 442, 592, 410, 590, 416, 670, 414,\n",
       "       447, 537, 434, 566, 444, 392, 601, 402, 521, 604, 342, 602, 569,\n",
       "       628, 398, 427, 413, 433, 377, 617, 645, 507, 630, 363, 650, 568,\n",
       "       673, 448, 458, 513, 616, 428, 439, 391, 369, 649, 404, 388, 610,\n",
       "       445, 409, 364, 383, 506, 591, 423, 450, 411, 367, 401, 408, 460,\n",
       "       443, 538, 435, 426, 432, 441, 464, 390, 376, 429, 466, 417, 567,\n",
       "       449, 438, 397, 378, 396, 375, 405, 471, 436, 451, 358, 393, 461,\n",
       "       420, 419, 470, 424, 425, 359, 370, 406, 440, 629, 352, 418, 356,\n",
       "       357, 346, 350, 345, 355, 412, 343, 437, 407, 351, 465, 344, 353,\n",
       "       360, 347, 354, 349, 348, 361], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordena los índice según los valores de similaridad de mayor a menor\n",
    "# Te dice qué documentos tienen las similaridades más altas\n",
    "np.argsort(cossim)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c006b6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 1.0000 contra el fragmento \"10\" de \"lobo_espacial\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.7279 contra el fragmento \"9\" de \"lobo_espacial\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.7142 contra el fragmento \"11\" de \"lobo_espacial\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.3138 contra el fragmento \"475\" de \"neuromante\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.3066 contra el fragmento \"785\" de \"neuromante\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.2803 contra el fragmento \"362\" de \"don_quijote\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.2237 contra el fragmento \"343\" de \"deepfake\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.2500 contra el fragmento \"460\" de \"don_quijote\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.2392 contra el fragmento \"461\" de \"ia_articulo\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.2726 contra el fragmento \"474\" de \"ia_articulo\"\n",
      "Comparamos fragmento \"10\" con Etiquetas/Clases \"lobo_espacial\" donde el valor de similaridad es de 0.1403 contra el fragmento \"361\" de \"deepfake\"\n"
     ]
    }
   ],
   "source": [
    "# Calculamos valor de similitud contra fragmentos específicos de multiples documentos\n",
    "idx_doc_lista = [10, 9, 11,475,785, 362,343,460,461,474,361]  # Lista de documentos a comparar\n",
    "\n",
    "for idx_doc in idx_doc_lista:\n",
    "    # CALCULAR SIMILITUD DIRECTA ENTRE DOS DOCUMENTOS\n",
    "    similitud_doidx = cosine_similarity(X_train[idx], X_train[idx_doc])[0][0]\n",
    "    print(f'Comparamos fragmento \"{idx}\" con Etiquetas/Clases \"{df_train['etiqueta'].iloc[idx]}\" donde el valor de similaridad es de {similitud_doidx:.4f} contra el fragmento \"{idx_doc}\" de \"{df_train['etiqueta'].iloc[idx_doc]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c4b876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 11 14 15 13]\n"
     ]
    }
   ],
   "source": [
    "# ----------------#Toma los índices ordenados por similaridad y limitando la cantidad de resultado- \n",
    "#Excluye el primero [1:] (el documento consigo mismo)\n",
    "#Toma los siguientes 5 [1:6]\n",
    "#Resultado: [0, 3, 4, 1] (los 4 más similares, excluyendo él mismo)\n",
    "#¿Por qué excluir el primero?\n",
    "#El documento más similar a sí mismo es él mismo (similaridad = 1.0)\n",
    "mostsim = np.argsort(cossim)[::-1][1:6] # son los documentos MÁS similares (excluyendo él mismo)\n",
    "print (mostsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26585bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta del Documento de consulta: 'lobo_espacial' (fragmento:  10)\n",
      "\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 10 -> valor de similaridad: 1.0000\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 9 -> valor de similaridad: 0.7279\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 11 -> valor de similaridad: 0.7142\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 14 -> valor de similaridad: 0.4791\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 15 -> valor de similaridad: 0.4604\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 13 -> valor de similaridad: 0.4563\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 16 -> valor de similaridad: 0.4533\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 12 -> valor de similaridad: 0.4457\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 17 -> valor de similaridad: 0.4374\n",
      "Etiquetas / Clases: lobo_espacial -> documento: 76 -> valor de similaridad: 0.4320\n"
     ]
    }
   ],
   "source": [
    "# Listado por rango de similitud top 10 \n",
    "\n",
    "#idx = 120\n",
    "# Etiqueta del documento de consulta\n",
    "etiqueta_consulta = df_train['etiqueta'].iloc[idx]\n",
    "print(f\"Etiqueta del Documento de consulta: '{etiqueta_consulta}' (fragmento:  {idx})\\n\")\n",
    "\n",
    "# Calcula la similitud entre un documento y todos los demás\n",
    "cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
    "# Obtener índices ordenados por similitud (de mayor a menor)\n",
    "# no excluimos el documento de similarity 1, estamos consiente que es un resultado obtenido por compararse a sí mismo es él mismo\n",
    "indices_similitud = np.argsort(cossim)[::-1]\n",
    "# Obtener valores de similitud ordenados\n",
    "documentos_similitud = np.sort(cossim)[::-1]\n",
    "\n",
    "# Mostrar los 10 documentos más similares\n",
    "## print (f' Etiquetas / Clases:   {df_train['etiqueta'].iloc[10]} ')   # individual \n",
    "# grupal \n",
    "for i in range(10):  # Top 10\n",
    "    doc_idx = indices_similitud[i]\n",
    "    etiqueta = df_train['etiqueta'].iloc[doc_idx]\n",
    "    valor_sim = documentos_similitud[i]\n",
    "    print(f\"Etiquetas / Clases: {etiqueta} -> documento: {doc_idx} -> valor de similaridad: {valor_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b49ed",
   "metadata": {},
   "source": [
    "<h3><a href=\"#2\">Punto 2</a></h3>\n",
    "\n",
    "### Modelo de clasificación Naïve Bayes\n",
    "\n",
    "Naïve Bayes es un algoritmo probabilístico que clasifica documentos calculando qué tan probable es que pertenezcan a cada clase, basándose en las palabras que contienen.\n",
    "- Modelo de Naïve Bayes Multinomial. Es la Versión \"clásica\" de Naïve Bayes para texto, es bueno cuando tiene las clases balanceadas, Cuenta frecuencias de palabras directamente Aprendiendo \"¿Qué palabras aparecen en documentos de clase X?\"\n",
    "\n",
    "    Ejemplo el modelo para clasificar un documento, pregunta, ¿Qué tan probable es que 'armadura' aparezca en lobo_espacial?, ¿Qué tan probable es que 'ciberespacio' aparezca en neuromante?\n",
    "\n",
    "- Modelo de Naïve Bayes ComplementNB. Versión mejorada diseñada para clases desbalanceadas, En lugar de aprender de documentos de la clase, aprende de documentos de todas las otras clases aprendiendo  \"¿Qué palabras NO aparecen en las otras clases?\"\n",
    "\n",
    "    Ejemplo el modelo para clasificar como 'lobo_espacial', pregunta: ¿Qué tan diferentes son estas palabras de neuromante, don_quijote, etc.?\n",
    "\n",
    "=================================0\n",
    "\n",
    "- Multinomial -> Funciona bien con CountVectorizer\n",
    "- ComplementNB ->  Funciona bien con TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b79a0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preparados para los modelos Naïve Bayes:\n",
      "   X_train shape: (786, 20713)\n",
      "   X_test shape: (786, 20713) \n",
      "\n",
      "   Clases: ['lobo_espacial', 'deepfake', 'don_quijote', 'ia_articulo', 'neuromante']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# librerías \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ==========================================\n",
    "# Train/Test (100% de los datos)\n",
    "# ==========================================\n",
    "## Parámetros del Vectorizador (TfidfVectorizer)\n",
    "tfidfvect = TfidfVectorizer()\n",
    "X_train = tfidfvect.fit_transform(df_train['texto'])\n",
    "X_test = tfidfvect.transform(df_test['texto'])  # Solo transform, no fit\n",
    "\n",
    "# Etiquetas\n",
    "y_train = df_train['etiqueta']\n",
    "y_test = df_test['etiqueta']\n",
    "\n",
    "print(\"Datos preparados para los modelos Naïve Bayes:\")\n",
    "print(f\"   X_train shape: {X_train.shape}\")\n",
    "print(f\"   X_test shape: {X_test.shape} \\n\")\n",
    "print(f\"   Clases: {list(df_train['etiqueta'].unique())}\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6d3949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** MULTINOMIAL NAIVE BAYES ***\n",
      "F1-score (macro): 0.5577733084525537\n",
      "Predicciones realizadas: 786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Modelo Multinomial Naive Bayes\n",
    "# ==========================================\n",
    "\n",
    "print(\"*** MULTINOMIAL NAIVE BAYES ***\")\n",
    "\n",
    "# Instanciar y entrenar modelo\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "\n",
    "# F1-score macro\n",
    "f1_mnb = f1_score(y_test, y_pred_mnb, average='macro')\n",
    "\n",
    "print(f\"F1-score (macro): {f1_mnb}\")\n",
    "print(f\"Predicciones realizadas: {len(y_pred_mnb)}\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5af755",
   "metadata": {},
   "source": [
    "**¿Por qué vemos que  ComplementNB superó a MultinomialNB?**\n",
    "\n",
    "ComplementNB **tiene un mejor Manejo de clases desbalanceadas:**\n",
    "- ComplementNB fue diseñado específicamente para corregir problemas de MultinomialNB\n",
    "- Es más robusto cuando hay clases con pocos ejemplos\n",
    "- En nuestro ejemplo tenemos un dataset desbalanceado algunas clases tienen más fragmentos que otras\n",
    "\n",
    "En comparación entre los 2 modelos tenemos que\n",
    "- **MultinomialNB:**\n",
    "  - Estima probabilidades usando SOLO ejemplos de cada clase\n",
    "  - Puede sufrir de \"sesgo\" hacia clases dominantes\n",
    "- **ComplementNB:**\n",
    "  - Estima probabilidades usando ejemplos de TODAS las otras clases\n",
    "  - Más equilibrado y menos propenso a sesgos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddaaccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** COMPLEMENT NAIVE BAYES***\n",
      "------------------------------\n",
      "F1-score (macro): 1.0\n",
      "Predicciones realizadas: 786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# Modelo Complement Naive Bayes\n",
    "# ==========================================\n",
    "\n",
    "print(\"*** COMPLEMENT NAIVE BAYES***\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Instanciar y entrenar modelo\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "\n",
    "# F1-score macro\n",
    "f1_cnb = f1_score(y_test, y_pred_cnb, average='macro')\n",
    "\n",
    "print(f\"F1-score (macro): {f1_cnb}\")\n",
    "print(f\"Predicciones realizadas: {len(y_pred_cnb)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c0302",
   "metadata": {},
   "source": [
    "#### Tipos de vectorización  en los modelos \n",
    "Algoritmo: Naïve Bayes (la lógica matemática)\n",
    "Modelos: MultinomialNB y ComplementNB (implementaciones específicas)\n",
    "Vectorizadores: CountVectorizer y TF-IDF (preprocesamiento de texto)\n",
    "\n",
    "\n",
    "\n",
    "- CountVectorizer. Convierte texto en números contando cuántas veces aparece cada palabra.\n",
    "- TF-IDF (Term Frequency - Inverse Document Frequency). Convierte texto en números, pero pondera la importancia de cada palabra\n",
    "\n",
    "| Aspecto | CountVectorizer | TF-IDF |\n",
    "|---------|-----------------|--------|\n",
    "| **Valores** | Enteros (0, 1, 2, 3...) | Decimales (0.0 - 1.0) |\n",
    "| **Enfoque** | \"¿Cuántas veces aparece?\" | \"¿Qué tan importante es?\" |\n",
    "| **Palabras comunes** | Peso alto si aparecen mucho | Peso bajo automáticamente |\n",
    "| **Palabras raras** | Peso según frecuencia | Peso alto si son distintivas |\n",
    "| **Interpretación** | Muy fácil | Requiere entendimiento |\n",
    "|Analogía Simple|¿Cuántas veces vio 'armadura'? → 5 veces| ¿Cuántas veces vio 'armadura' Y qué tan importante es esa palabra? → 'Armadura' aparece 5 veces, y es muy rara en otros textos, así que vale 0.85|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37d840a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicciones realizadas MultinomialNB: 786 = 786\n",
      "   Predicciones realizadas ComplementNB: 786 = 786 \n",
      "============================================================\n",
      "COMPARACIÓN DE MODELOS CON VECTORIZACIÓN  CountVectorizer \n",
      "MultinomialNB CountVectorizer   F1-score (macro): 1.0\n",
      "ComplementNB CountVectorizer     F1-score (macro): 1.0\n",
      "** Empate **\n",
      "----------------------------------------\n",
      "COMPARACIÓN DE MODELOS CON VECTORIZACIÓN TfidfVectorizer\n",
      "MultinomialNB  TfidfVectorizer  F1-score (macro): 0.5577733084525537\n",
      "ComplementNB   TfidfVectorizer  F1-score (macro): 1.0\n",
      "Ganador: ComplementNB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "#from sklearn.metrics import f1_score\n",
    "#==========================================\n",
    "# Parámetros del Vectorizador (CountVectotizer)\n",
    "countvect = CountVectorizer()\n",
    "X_train_countvect = countvect.fit_transform(df_train['texto'])\n",
    "X_test_countvect = countvect.transform(df_test['texto'])  # Solo transform, no fit\n",
    "\n",
    "# Etiquetas\n",
    "y_train_countvect = df_train['etiqueta']\n",
    "y_test_countvect = df_test['etiqueta']\n",
    "\n",
    "\"\"\" \n",
    "agrego el código de para tener una secuencia en el bloque \n",
    "en bloques previos calculamos los modelos utilizando el Vectorizador  TfidfVectorizer (TF-IDF)\n",
    "\"\"\"\n",
    "##==========================================b\n",
    "## Parámetros del Vectorizador (TfidfVectorizer)\n",
    "#tfidfvect = TfidfVectorizer()\n",
    "#X_train = tfidfvect.fit_transform(df_train['texto'])\n",
    "#X_test = tfidfvect.transform(df_test['texto'])  # Solo transform, no fit\n",
    "\n",
    "## Etiquetas\n",
    "#y_train = df_train['etiqueta']\n",
    "#y_test = df_test['etiqueta']\n",
    "\n",
    "\n",
    "# ******************************************************************************************\n",
    "# modelos MultinomialNB y ComplementNB con vectorización CountVectorizer\n",
    "#==============================\n",
    "#  Multinomial Naive Bayes\n",
    "# =============================\n",
    "\n",
    "# Instanciar y entrenar modelo\n",
    "#mnb_countvect = MultinomialNB(alpha=var_alpha)\n",
    "mnb_countvect = MultinomialNB()\n",
    "mnb_countvect.fit(X_train_countvect, y_train_countvect)\n",
    "# Predicciones\n",
    "y_pred_mnb_countvect = mnb_countvect.predict(X_test_countvect)\n",
    "# F1-score macro\n",
    "f1_mnb_countvect = f1_score(y_test_countvect, y_pred_mnb_countvect, average='macro')\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Complement Naive Bayes\n",
    "# ==========================================\n",
    "\n",
    "# Instanciar y entrenar modelo\n",
    "#cnb_countvect = ComplementNB(alpha=var_alpha)\n",
    "cnb_countvect = ComplementNB()\n",
    "#cnb_countvect = ComplementNB(norm=True) # Con normalización\n",
    "cnb_countvect.fit(X_train_countvect, y_train_countvect)\n",
    "# Predicciones\n",
    "y_pred_cnb_countvect = cnb_countvect.predict(X_test_countvect)\n",
    "# F1-score macro\n",
    "f1_cnb_countvect = f1_score(y_test_countvect, y_pred_cnb_countvect, average='macro')\n",
    "\n",
    "\n",
    "# ******************************************************************************************\n",
    "\n",
    "\n",
    "print(f\"   Predicciones realizadas MultinomialNB: {len(y_pred_cnb_countvect)} = {len(y_pred_cnb)}\")\n",
    "print(f\"   Predicciones realizadas ComplementNB: {len(y_pred_cnb_countvect)} = {len(y_pred_cnb)} \")\n",
    "\n",
    "# ==================================================\n",
    "# COMPARACIÓN DE MODELOS CON VECTORIZACIÓN  CountVectorizer\n",
    "# ==================================================\n",
    "print(\"=\" * 60)\n",
    "print(f\"COMPARACIÓN DE MODELOS CON VECTORIZACIÓN  CountVectorizer \")\n",
    "print(f\"MultinomialNB CountVectorizer   F1-score (macro): {f1_mnb_countvect}\")\n",
    "print(f\"ComplementNB CountVectorizer     F1-score (macro): {f1_cnb_countvect}\")\n",
    "\n",
    "\n",
    "if f1_mnb_countvect > f1_cnb_countvect:\n",
    "    print(\"Ganador: MultinomialNB\")\n",
    "elif f1_cnb_countvect > f1_mnb_countvect:\n",
    "    print(\"Ganador: ComplementNB\") \n",
    "else:\n",
    "    print(\"** Empate **\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ================================================\n",
    "# COMPARACIÓN DE MODELOS CON VECTORIZACIÓN TfidfVectorizer\n",
    "# ================================================\n",
    "\n",
    "print(\"COMPARACIÓN DE MODELOS CON VECTORIZACIÓN TfidfVectorizer\")\n",
    "print(f\"MultinomialNB  TfidfVectorizer  F1-score (macro): {f1_mnb}\")\n",
    "print(f\"ComplementNB   TfidfVectorizer  F1-score (macro): {f1_cnb}\")\n",
    "\n",
    "# *************************************\n",
    "if f1_mnb > f1_cnb:\n",
    "    print(\"Ganador: MultinomialNB\")\n",
    "elif f1_cnb > f1_mnb:\n",
    "    print(\"Ganador: ComplementNB\") \n",
    "else:\n",
    "    print(\"** Empate **\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fdfbe8",
   "metadata": {},
   "source": [
    "En este ejemplo podemos ver que CountVectorizer funcionó mejor con MultinomialNB a causa de : \n",
    "- El  dataset tiene vocabulario muy específico por clase (EL contexto literario de cada clase es muy distinto) esto dificulta que TF-IDF realice comparación en el vocabulario entre las clases. \n",
    "-  Adicionalmente se el modelo  MultinomialNB esta optimizado para ser utilizado con CountVectorizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be5679",
   "metadata": {},
   "source": [
    "<h3><a href=\"#3\">Punto 3</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bea51f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">\n",
    "\t<h1 style=\"display: inline-block;margin: 0;padding: 8px 16px;color: white;background: linear-gradient(to right,rgb(17, 75, 141), #4CAF50);border-radius: 12px;font-size: 1.8rem;box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);\">Teoria</h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Transponer la matriz documento-término\n",
    "\n",
    "#### ¿Qué es la matriz documento-término?\n",
    "\n",
    "Cuando usas un vectorizador como `CountVectorizer` o `TfidfVectorizer` sobre tu colección de documentos (corpus), el resultado es una **matriz documento-término**.\n",
    "\n",
    "- **Filas:** Representan cada uno de tus documentos.\n",
    "    \n",
    "- **Columnas:** Representan cada término (palabra o n-grama) único que se encontró en tu vocabulario.\n",
    "    \n",
    "- **Valores:** Son los recuentos (`CountVectorizer`) o los valores TF-IDF (`TfidfVectorizer`) de cada término en cada documento.\n",
    "    \n",
    "\n",
    "Piensa en ella como una tabla donde cada fila es un documento y cada columna es una palabra, y las celdas indican la presencia/importancia de esa palabra en ese documento.\n",
    "\n",
    "#### ¿Qué es transponerla?\n",
    "\n",
    "**Transponer una matriz** significa intercambiar sus filas por sus columnas. Si tu matriz original tiene M filas (documentos) y N columnas (términos), la matriz transpuesta tendrá N filas (términos) y M columnas (documentos).\n",
    "\n",
    "- **Matriz original (Documento-Término):**\n",
    "    \n",
    "    ```\n",
    "            Palabra1  Palabra2  Palabra3 ...\n",
    "    Doc1       0.5       0.2       0.0\n",
    "    Doc2       0.1       0.7       0.3\n",
    "    Doc3       0.0       0.1       0.9   ...\n",
    "    ```\n",
    "    \n",
    "- **Matriz Transpuesta (Término-Documento):**\n",
    "    \n",
    "    ```\n",
    "               Doc1      Doc2      Doc3 ...\n",
    "    Palabra1   0.5       0.1       0.0\n",
    "    Palabra2   0.2       0.7       0.1\n",
    "    Palabra3   0.0       0.3       0.9  ...\n",
    "    ```\n",
    "    \n",
    "\n",
    "#### ¿Cómo se obtiene una \"vectorización de palabras\"?\n",
    "\n",
    "En la matriz transpuesta, cada **fila** ahora representa una palabra, y los valores en esa fila (`[0.5, 0.1, 0.0]` para `Palabra1` en el ejemplo) son su \"vector\". Este vector describe la **distribución de esa palabra a través de todos los documentos**. Palabras que tienen vectores similares (es decir, que aparecen en los mismos documentos con patrones de frecuencia/TF-IDF similares) se consideran semánticamente relacionadas o contextualmente parecidas.\n",
    "\n",
    "#### ¿Cómo hacerlo en Python?\n",
    "\n",
    "Después de haber vectorizado tu corpus (usando `CountVectorizer` o `TfidfVectorizer`), obtendrás una matriz dispersa (`X`). Para transponerla:\n",
    "\n",
    "\n",
    "\n",
    "```Python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Suponiendo que 'corpus' es tu lista de documentos de texto\n",
    "# ... (código para cargar y preparar df['texto'] como corpus) ...\n",
    "\n",
    "# 1. Vectorizar el texto (ejemplo con TfidfVectorizer)\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='spanish') # Ajusta tus parámetros\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# 2. Obtener los nombres de las características (las palabras/n-gramas del vocabulario)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 3. Transponer la matriz\n",
    "# Si X es una matriz dispersa (csr_matrix o csc_matrix), puedes usar .T\n",
    "X_transposed = X.T\n",
    "\n",
    "print(f\"Forma original de la matriz (Documento-Término): {X.shape}\")\n",
    "print(f\"Forma de la matriz transpuesta (Término-Documento): {X_transposed.shape}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c74858db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 15 palabras significativas (≥7 caracteres):\n",
      " 1. 'quijote' → 19.64\n",
      "      Aparece en 98 documentos:\n",
      "        Etiqueta/Clase: don_quijote -> documento: 439 -> valor: 0.3433\n",
      "        Etiqueta/Clase: don_quijote -> documento: 411 -> valor: 0.3232\n",
      "        Etiqueta/Clase: don_quijote -> documento: 397 -> valor: 0.3197\n",
      "        Etiqueta/Clase: don_quijote -> documento: 457 -> valor: 0.3125\n",
      "        Etiqueta/Clase: don_quijote -> documento: 455 -> valor: 0.3105\n",
      "        ... y 93 documentos más\n",
      "\n",
      " 2. 'mientras' → 11.58\n",
      "      Aparece en 446 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 741 -> valor: 0.0917\n",
      "        Etiqueta/Clase: neuromante -> documento: 740 -> valor: 0.0889\n",
      "        Etiqueta/Clase: neuromante -> documento: 785 -> valor: 0.0829\n",
      "        Etiqueta/Clase: neuromante -> documento: 757 -> valor: 0.0761\n",
      "        Etiqueta/Clase: neuromante -> documento: 756 -> valor: 0.0761\n",
      "        ... y 441 documentos más\n",
      "\n",
      " 3. 'strybjorn' → 11.57\n",
      "      Aparece en 168 documentos:\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 98 -> valor: 0.2651\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 324 -> valor: 0.2458\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 74 -> valor: 0.2314\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 75 -> valor: 0.2257\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 319 -> valor: 0.2204\n",
      "        ... y 163 documentos más\n",
      "\n",
      " 4. 'estaban' → 9.46\n",
      "      Aparece en 312 documentos:\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 61 -> valor: 0.1269\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 250 -> valor: 0.1155\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 76 -> valor: 0.1065\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 86 -> valor: 0.0972\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 206 -> valor: 0.0965\n",
      "        ... y 307 documentos más\n",
      "\n",
      " 5. 'armitage' → 9.30\n",
      "      Aparece en 134 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 593 -> valor: 0.2365\n",
      "        Etiqueta/Clase: neuromante -> documento: 626 -> valor: 0.2023\n",
      "        Etiqueta/Clase: neuromante -> documento: 604 -> valor: 0.1798\n",
      "        Etiqueta/Clase: neuromante -> documento: 600 -> valor: 0.1765\n",
      "        Etiqueta/Clase: neuromante -> documento: 711 -> valor: 0.1746\n",
      "        ... y 129 documentos más\n",
      "\n",
      " 6. 'también' → 9.27\n",
      "      Aparece en 365 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 758 -> valor: 0.0879\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 270 -> valor: 0.0860\n",
      "        Etiqueta/Clase: neuromante -> documento: 517 -> valor: 0.0829\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 219 -> valor: 0.0727\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 87 -> valor: 0.0717\n",
      "        ... y 360 documentos más\n",
      "\n",
      " 7. 'momento' → 8.64\n",
      "      Aparece en 335 documentos:\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 211 -> valor: 0.0947\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 210 -> valor: 0.0930\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 296 -> valor: 0.0856\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 291 -> valor: 0.0851\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 71 -> valor: 0.0739\n",
      "        ... y 330 documentos más\n",
      "\n",
      " 8. 'maelcum' → 8.56\n",
      "      Aparece en 72 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 764 -> valor: 0.4120\n",
      "        Etiqueta/Clase: neuromante -> documento: 763 -> valor: 0.3674\n",
      "        Etiqueta/Clase: neuromante -> documento: 608 -> valor: 0.2696\n",
      "        Etiqueta/Clase: neuromante -> documento: 704 -> valor: 0.2538\n",
      "        Etiqueta/Clase: neuromante -> documento: 728 -> valor: 0.2475\n",
      "        ... y 67 documentos más\n",
      "\n",
      " 9. 'parecía' → 8.29\n",
      "      Aparece en 328 documentos:\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 143 -> valor: 0.1003\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 91 -> valor: 0.0890\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 90 -> valor: 0.0883\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 144 -> valor: 0.0755\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 77 -> valor: 0.0751\n",
      "        ... y 323 documentos más\n",
      "\n",
      "10. 'después' → 8.23\n",
      "      Aparece en 355 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 523 -> valor: 0.0666\n",
      "        Etiqueta/Clase: neuromante -> documento: 500 -> valor: 0.0648\n",
      "        Etiqueta/Clase: neuromante -> documento: 504 -> valor: 0.0619\n",
      "        Etiqueta/Clase: neuromante -> documento: 477 -> valor: 0.0601\n",
      "        Etiqueta/Clase: neuromante -> documento: 508 -> valor: 0.0537\n",
      "        ... y 350 documentos más\n",
      "\n",
      "11. 'preguntó' → 7.70\n",
      "      Aparece en 285 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 626 -> valor: 0.0921\n",
      "        Etiqueta/Clase: neuromante -> documento: 661 -> valor: 0.0906\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 141 -> valor: 0.0811\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 140 -> valor: 0.0804\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 109 -> valor: 0.0789\n",
      "        ... y 280 documentos más\n",
      "\n",
      "12. 'caballero' → 7.56\n",
      "      Aparece en 91 documentos:\n",
      "        Etiqueta/Clase: don_quijote -> documento: 413 -> valor: 0.2449\n",
      "        Etiqueta/Clase: don_quijote -> documento: 412 -> valor: 0.2373\n",
      "        Etiqueta/Clase: don_quijote -> documento: 444 -> valor: 0.2343\n",
      "        Etiqueta/Clase: don_quijote -> documento: 445 -> valor: 0.2090\n",
      "        Etiqueta/Clase: don_quijote -> documento: 409 -> valor: 0.1986\n",
      "        ... y 86 documentos más\n",
      "\n",
      "13. 'riviera' → 7.21\n",
      "      Aparece en 79 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 639 -> valor: 0.3421\n",
      "        Etiqueta/Clase: neuromante -> documento: 636 -> valor: 0.2941\n",
      "        Etiqueta/Clase: neuromante -> documento: 603 -> valor: 0.2758\n",
      "        Etiqueta/Clase: neuromante -> documento: 768 -> valor: 0.2499\n",
      "        Etiqueta/Clase: neuromante -> documento: 604 -> valor: 0.2444\n",
      "        ... y 74 documentos más\n",
      "\n",
      "14. 'finlandés' → 6.74\n",
      "      Aparece en 75 documentos:\n",
      "        Etiqueta/Clase: neuromante -> documento: 565 -> valor: 0.3203\n",
      "        Etiqueta/Clase: neuromante -> documento: 672 -> valor: 0.2928\n",
      "        Etiqueta/Clase: neuromante -> documento: 564 -> valor: 0.2705\n",
      "        Etiqueta/Clase: neuromante -> documento: 673 -> valor: 0.2617\n",
      "        Etiqueta/Clase: neuromante -> documento: 715 -> valor: 0.2537\n",
      "        ... y 70 documentos más\n",
      "\n",
      "15. 'respondió' → 6.70\n",
      "      Aparece en 247 documentos:\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 110 -> valor: 0.0856\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 111 -> valor: 0.0832\n",
      "        Etiqueta/Clase: neuromante -> documento: 633 -> valor: 0.0769\n",
      "        Etiqueta/Clase: neuromante -> documento: 758 -> valor: 0.0644\n",
      "        Etiqueta/Clase: lobo_espacial -> documento: 109 -> valor: 0.0634\n",
      "        ... y 242 documentos más\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Búsqueda de palabras mas comunes por cantidad de caracteres. \n",
    "import numpy as np\n",
    "# min_length = cantidad de palabras (min_length=5\n",
    "def analizar_palabras_por_longitud(top_n,vectorizer, X_matrix, min_length, df_datos=None, mostrar_documentos=True):\n",
    "    \"\"\"\n",
    "    Analiza palabras filtradas por longitud mínima para evitar artículos/preposiciones\n",
    "    \n",
    "    Args:\n",
    "        vectorizer: vectorizador entrenado\n",
    "        X_matrix: matriz vectorizada\n",
    "        min_length: longitud mínima de palabras\n",
    "        df_datos: DataFrame con los datos (opcional, para mostrar documentos)\n",
    "        mostrar_documentos: si mostrar en qué documentos aparece cada palabra\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    if hasattr(X_matrix, 'toarray'):\n",
    "        frecuencias_totales = np.array(X_matrix.sum(axis=0)).flatten()\n",
    "        X_dense = X_matrix.toarray()\n",
    "    else:\n",
    "        frecuencias_totales = X_matrix.sum(axis=0)\n",
    "        X_dense = X_matrix\n",
    "    \n",
    "    # Filtrar palabras por longitud\n",
    "    palabras_largas = []\n",
    "    for palabra, freq in zip(feature_names, frecuencias_totales):\n",
    "        if len(palabra) >= min_length:\n",
    "            palabras_largas.append((palabra, freq))\n",
    "    \n",
    "    # Ordenar y mostrar top 15\n",
    "    palabras_largas = sorted(palabras_largas, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"TOP {top_n} palabras significativas (≥{min_length} caracteres):\")\n",
    "    \n",
    "    for i, (palabra, frecuencia) in enumerate(palabras_largas[:top_n], 1):\n",
    "        print(f\"{i:2d}. '{palabra}' → {frecuencia:.2f}\")\n",
    "        \n",
    "        # Mostrar documentos donde aparece la palabra si se solicita\n",
    "        if mostrar_documentos and df_datos is not None:\n",
    "            # Obtener índice de la palabra en el vocabulario\n",
    "            palabra_idx = vectorizer.vocabulary_[palabra]\n",
    "            \n",
    "            # Encontrar documentos donde la palabra tiene valor > 0\n",
    "            docs_con_palabra = []\n",
    "            for doc_idx in range(X_dense.shape[0]):\n",
    "                if X_dense[doc_idx, palabra_idx] > 0:\n",
    "                    etiqueta = df_datos['etiqueta'].iloc[doc_idx]\n",
    "                    valor = X_dense[doc_idx, palabra_idx]\n",
    "                    docs_con_palabra.append((doc_idx, etiqueta, valor))\n",
    "            \n",
    "            # Ordenar por valor (frecuencia en el documento)\n",
    "            docs_con_palabra = sorted(docs_con_palabra, key=lambda x: x[2], reverse=True)\n",
    "            \n",
    "            print(f\"      Aparece en {len(docs_con_palabra)} documentos:\")\n",
    "            for doc_idx, etiqueta, valor in docs_con_palabra[:5]:  # Mostrar top 5\n",
    "                print(f\"        Etiqueta/Clase: {etiqueta} -> documento: {doc_idx} -> valor: {valor:.4f}\")\n",
    "            \n",
    "            if len(docs_con_palabra) > 5:\n",
    "                print(f\"        ... y {len(docs_con_palabra) - 5} documentos más\")\n",
    "            print()\n",
    "    \n",
    "    return palabras_largas\n",
    "\n",
    "\n",
    "#analisis=  analizar_palabras_por_longitud(tfidfvect, X_train)\n",
    "#analisis = analizar_palabras_por_longitud(tfidfvect, X_train, df_datos=df, mostrar_documentos=True)\n",
    "# 7 representa el numero de caracteres\n",
    "analisis = analizar_palabras_por_longitud(15, tfidfvect, X_train,7, df_datos=df)\n",
    "#analisis = analizar_palabras_por_longitud(15, countvect, X_train,7, df_datos=df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae2575cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 5 PALABRAS MÁS FRECUENTES EN TODO EL TEXTO :\n",
      "----------------------------------------\n",
      " 1. 'de' → 250.16 veces\n",
      " 2. 'que' → 152.95 veces\n",
      " 3. 'la' → 149.30 veces\n",
      " 4. 'el' → 110.17 veces\n",
      " 5. 'en' → 89.58 veces\n"
     ]
    }
   ],
   "source": [
    "# Búsqueda de palabras mas comunes entre todo los documentos \n",
    "def obtener_top_palabras_frecuentes(vectorizer, X_matrix, top_n=1):\n",
    "    \"\"\"\n",
    "    Obtiene las palabras más frecuentes del dataset vectorizado\n",
    "    \n",
    "    Args:\n",
    "        vectorizer: vectorizador ya entrenado (CountVectorizer o TfidfVectorizer)\n",
    "        X_matrix: matriz vectorizada (documento-término)\n",
    "        top_n: número de palabras a mostrar\n",
    "    \n",
    "    Returns:\n",
    "        lista de tuplas (palabra, frecuencia_total)\n",
    "    \"\"\"\n",
    "        \n",
    "    # Obtener nombres de las características (palabras)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Sumar frecuencias por columna (cada columna es una palabra)\n",
    "    if hasattr(X_matrix, 'toarray'):\n",
    "        # Para matrices dispersas (sparse)\n",
    "        frecuencias_totales = np.array(X_matrix.sum(axis=0)).flatten()\n",
    "    else:\n",
    "        # Para matrices densas\n",
    "        frecuencias_totales = X_matrix.sum(axis=0)\n",
    "    \n",
    "    # Crear pares (palabra, frecuencia)\n",
    "    palabra_frecuencia = list(zip(feature_names, frecuencias_totales))\n",
    "    \n",
    "    # Ordenar por frecuencia (mayor a menor)\n",
    "    palabra_frecuencia_sorted = sorted(palabra_frecuencia, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Mostrar TOP N\n",
    "    print(f\"TOP {top_n} PALABRAS MÁS FRECUENTES EN TODO EL TEXTO :\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    top_palabras = palabra_frecuencia_sorted[:top_n]\n",
    "    \n",
    "    for i, (palabra, frecuencia) in enumerate(top_palabras, 1):\n",
    "        print(f\"{i:2d}. '{palabra}' → {frecuencia:.2f} veces\")\n",
    "    \n",
    "    #print()\n",
    "    #print(f\" Estadísticas del vocabulario:\")\n",
    "    #print(f\"   Total de palabras únicas: {len(feature_names)}\")\n",
    "    #print(f\"   Frecuencia máxima: {max(frecuencias_totales):.2f}\")\n",
    "    #print(f\"   Frecuencia mínima: {min(frecuencias_totales):.2f}\")\n",
    "    #print(f\"   Frecuencia promedio: {np.mean(frecuencias_totales):.2f}\")\n",
    "    \n",
    "    return top_palabras\n",
    "\n",
    "\n",
    "top_10 = obtener_top_palabras_frecuentes(tfidfvect, X_train, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79be0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ANÁLISIS DE SIMILARIDAD ENTRE PALABRAS \n",
      "======================================================================\n",
      "\n",
      " Matriz original: documento-término (786, 20713)\n",
      " Matriz transpuesta: término-documento (20713, 786)\n",
      "\n",
      "VERIFICACIÓN DE PALABRAS EN VOCABULARIO:\n",
      "--------------------------------------------------\n",
      " 'momento' - ENCONTRADA (índice: 13095)\n",
      " 'respondió' - ENCONTRADA (índice: 17036)\n",
      " 'preguntó' - ENCONTRADA (índice: 15425)\n",
      " 'después' - ENCONTRADA (índice: 6351)\n",
      " 'también' - ENCONTRADA (índice: 18868)\n",
      "\n",
      " similaridad de  5 palabras válidas\n",
      " análisis de similaridad de : --- MOMENTO ---\n",
      "============================================================\n",
      "Índice en vocabulario: 13095\n",
      "Contexto: Vector de 786 documentos\n",
      "Aparece en 335 documentos:\n",
      "    Documento 211 (lobo_espacial) → valor  TF-IDF: 0.094685\n",
      "    Documento 210 (lobo_espacial) → valor  TF-IDF: 0.093013\n",
      "    Documento 296 (lobo_espacial) → valor  TF-IDF: 0.085638\n",
      "    Documento 291 (lobo_espacial) → valor  TF-IDF: 0.085069\n",
      "    Documento 71 (lobo_espacial) → valor  TF-IDF: 0.073857\n",
      "   ... y 330 documentos más\n",
      "\n",
      "ESTADÍSTICAS DE SIMILARIDAD DE LA PALABRA EN EL ESPACIO DE VECTORES:\n",
      "   Similaridad de la palabra consigo misma: 1.0\n",
      "   Similaridad de la palabra promedio: 0.047337582922815286\n",
      "   Similaridad de la palabra máxima (sin incluirse): 0.6116738640598767\n",
      "   Similaridad de la palabra mínima: 0.0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      " análisis de similaridad de : --- RESPONDIÓ ---\n",
      "============================================================\n",
      "Índice en vocabulario: 17036\n",
      "Contexto: Vector de 786 documentos\n",
      "Aparece en 247 documentos:\n",
      "    Documento 110 (lobo_espacial) → valor  TF-IDF: 0.085563\n",
      "    Documento 111 (lobo_espacial) → valor  TF-IDF: 0.083220\n",
      "    Documento 633 (neuromante) → valor  TF-IDF: 0.076923\n",
      "    Documento 758 (neuromante) → valor  TF-IDF: 0.064399\n",
      "    Documento 109 (lobo_espacial) → valor  TF-IDF: 0.063365\n",
      "   ... y 242 documentos más\n",
      "\n",
      "ESTADÍSTICAS DE SIMILARIDAD DE LA PALABRA EN EL ESPACIO DE VECTORES:\n",
      "   Similaridad de la palabra consigo misma: 1.000000000000001\n",
      "   Similaridad de la palabra promedio: 0.0426888826846686\n",
      "   Similaridad de la palabra máxima (sin incluirse): 0.5639577452333829\n",
      "   Similaridad de la palabra mínima: 0.0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      " análisis de similaridad de : --- PREGUNTÓ ---\n",
      "============================================================\n",
      "Índice en vocabulario: 15425\n",
      "Contexto: Vector de 786 documentos\n",
      "Aparece en 285 documentos:\n",
      "    Documento 626 (neuromante) → valor  TF-IDF: 0.092077\n",
      "    Documento 661 (neuromante) → valor  TF-IDF: 0.090577\n",
      "    Documento 141 (lobo_espacial) → valor  TF-IDF: 0.081051\n",
      "    Documento 140 (lobo_espacial) → valor  TF-IDF: 0.080436\n",
      "    Documento 109 (lobo_espacial) → valor  TF-IDF: 0.078896\n",
      "   ... y 280 documentos más\n",
      "\n",
      "ESTADÍSTICAS DE SIMILARIDAD DE LA PALABRA EN EL ESPACIO DE VECTORES:\n",
      "   Similaridad de la palabra consigo misma: 0.9999999999999993\n",
      "   Similaridad de la palabra promedio: 0.045252348772123724\n",
      "   Similaridad de la palabra máxima (sin incluirse): 0.9999999999999993\n",
      "   Similaridad de la palabra mínima: 0.0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      " análisis de similaridad de : --- DESPUÉS ---\n",
      "============================================================\n",
      "Índice en vocabulario: 6351\n",
      "Contexto: Vector de 786 documentos\n",
      "Aparece en 355 documentos:\n",
      "    Documento 523 (neuromante) → valor  TF-IDF: 0.066578\n",
      "    Documento 500 (neuromante) → valor  TF-IDF: 0.064804\n",
      "    Documento 504 (neuromante) → valor  TF-IDF: 0.061853\n",
      "    Documento 477 (neuromante) → valor  TF-IDF: 0.060091\n",
      "    Documento 508 (neuromante) → valor  TF-IDF: 0.053653\n",
      "   ... y 350 documentos más\n",
      "\n",
      "ESTADÍSTICAS DE SIMILARIDAD DE LA PALABRA EN EL ESPACIO DE VECTORES:\n",
      "   Similaridad de la palabra consigo misma: 0.9999999999999996\n",
      "   Similaridad de la palabra promedio: 0.0535896060488412\n",
      "   Similaridad de la palabra máxima (sin incluirse): 0.9999999999999996\n",
      "   Similaridad de la palabra mínima: 0.0\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      " análisis de similaridad de : --- TAMBIÉN ---\n",
      "============================================================\n",
      "Índice en vocabulario: 18868\n",
      "Contexto: Vector de 786 documentos\n",
      "Aparece en 365 documentos:\n",
      "    Documento 758 (neuromante) → valor  TF-IDF: 0.087946\n",
      "    Documento 270 (lobo_espacial) → valor  TF-IDF: 0.085965\n",
      "    Documento 517 (neuromante) → valor  TF-IDF: 0.082941\n",
      "    Documento 219 (lobo_espacial) → valor  TF-IDF: 0.072669\n",
      "    Documento 87 (lobo_espacial) → valor  TF-IDF: 0.071707\n",
      "   ... y 360 documentos más\n",
      "\n",
      "ESTADÍSTICAS DE SIMILARIDAD DE LA PALABRA EN EL ESPACIO DE VECTORES:\n",
      "   Similaridad de la palabra consigo misma: 0.9999999999999987\n",
      "   Similaridad de la palabra promedio: 0.052088239956239686\n",
      "   Similaridad de la palabra máxima (sin incluirse): 0.9999999999999987\n",
      "   Similaridad de la palabra mínima: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def analizar_similaridad_palabra(X_transpuesta, vectorizer, palabra_objetivo, df_datos=None):\n",
    "    \"\"\"\n",
    "    Analiza la similaridad de una palabra específica con todas las demás\n",
    "    \n",
    "    Args:\n",
    "        X_transpuesta: matriz transpuesta (palabras x documentos)\n",
    "        vectorizer: vectorizador entrenado\n",
    "        palabra_objetivo: palabra a analizar\n",
    "        df_datos: DataFrame opcional para contexto adicional\n",
    "    \n",
    "    Returns:\n",
    "        diccionario con resultados del análisis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verificar si la palabra está en el vocabulario\n",
    "    if palabra_objetivo not in vectorizer.vocabulary_:\n",
    "        print(f\"ERRO: La palabra '{palabra_objetivo}' no está en el vocabulario\")\n",
    "        return None\n",
    "    \n",
    "    print(f\" análisis de similaridad de : --- {palabra_objetivo.upper()} ---\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Obtener índice de la palabra objetivo\n",
    "    idx_palabra = vectorizer.vocabulary_[palabra_objetivo]\n",
    "    ###feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    print(f\"Índice en vocabulario: {idx_palabra}\")\n",
    "    print(f\"Contexto: Vector de {X_transpuesta.shape[1]} documentos\")\n",
    "    \n",
    "\n",
    "    #--------------------------------\n",
    "    #TF-IDF Importancia relativa de esa palabra en ese documento vector_palabra\n",
    "    #TF: Qué tan frecuente es la palabra en ESE documento\n",
    "    #IDF: Qué tan rara es la palabra en TODO el corpus\n",
    "    #---------------------------------\n",
    "    # Mostrar en qué documentos aparece la palabra objetivo\n",
    "    if df_datos is not None:\n",
    "        vector_palabra = X_transpuesta[idx_palabra].toarray().flatten() if hasattr(X_transpuesta, 'toarray') else X_transpuesta[idx_palabra]\n",
    "        docs_con_palabra = []\n",
    "\n",
    "        for doc_idx, valor in enumerate(vector_palabra):\n",
    "            if valor > 0:\n",
    "                etiqueta = df_datos['etiqueta'].iloc[doc_idx]\n",
    "                docs_con_palabra.append((doc_idx, etiqueta, valor))\n",
    "        \n",
    "        docs_con_palabra = sorted(docs_con_palabra, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        print(f\"Aparece en {len(docs_con_palabra)} documentos:\")\n",
    "        for doc_idx, etiqueta, valor in docs_con_palabra[:5]:\n",
    "            print(f\"    Documento {doc_idx} ({etiqueta}) → valor  TF-IDF: {valor:.6f}\")\n",
    "            # 5 cantidad de resultados\n",
    "        if len(docs_con_palabra) > 5:\n",
    "            print(f\"   ... y {len(docs_con_palabra) - 5} documentos más\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Calcular similaridad coseno con todas las palabras\n",
    "    vector_objetivo = X_transpuesta[idx_palabra:idx_palabra+1]  # Mantener forma 2D\n",
    "    similaridades = cosine_similarity(vector_objetivo, X_transpuesta)[0]\n",
    "    \n",
    "    # Estadísticas de similaridad\n",
    "    print(f\"ESTADÍSTICAS DE SIMILARIDAD DE LA PALABRA EN EL ESPACIO DE VECTORES:\")\n",
    "    print(f\"   Similaridad de la palabra consigo misma: {similaridades[idx_palabra]}\")\n",
    "    print(f\"   Similaridad de la palabra promedio: {np.mean(similaridades)}\")\n",
    "    print(f\"   Similaridad de la palabra máxima (sin incluirse): {np.max(similaridades[similaridades < 1.0])}\")\n",
    "    print(f\"   Similaridad de la palabra mínima: {np.min(similaridades)}\")\n",
    "    print()\n",
    "  \n",
    "    return\n",
    "\n",
    "\n",
    "def analisis_completo_similaridad_palabras(X_train, vectorizer, palabras_buscar, df_datos=None):\n",
    "    \"\"\"\n",
    "    Trasponemos la matriz, Verificamos que la palabra exista, realizamos la vectorización \n",
    "    \"\"\"\n",
    "    print(\" ANÁLISIS DE SIMILARIDAD ENTRE PALABRAS \")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    # Transponer matriz\n",
    "    X_transpuesta = X_train.T\n",
    "    #  Matriz transpuesta: término-documento (filas=palabras, columnas=documentos)  \n",
    "    print(f\" Matriz original: documento-término {X_train.shape}\")\n",
    "    # Matriz transpuesta: término-documento (filas=palabras, columnas=documentos) \n",
    "    print(f\" Matriz transpuesta: término-documento {X_transpuesta.shape}\")\n",
    "    print()\n",
    "    \n",
    "    # Verificar que todas las palabras están en el vocabulario\n",
    "    print(\"VERIFICACIÓN DE PALABRAS EN VOCABULARIO:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    palabras_encontradas = []\n",
    "    for palabra in palabras_buscar:\n",
    "        if palabra in vectorizer.vocabulary_:\n",
    "            print(f\" '{palabra}' - ENCONTRADA (índice: {vectorizer.vocabulary_[palabra]})\")\n",
    "            palabras_encontradas.append(palabra)\n",
    "        else:\n",
    "            print(f\"ERRO: '{palabra}' - NO ENCONTRADA\")\n",
    "    \n",
    "    if not palabras_encontradas:\n",
    "        print(\"ERRO: No se encontraron palabras válidas para analizar\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n similaridad de  {len(palabras_encontradas)} palabras válidas\")\n",
    "\n",
    "    \n",
    "    # Analizar cada palabra\n",
    "    resultados = []\n",
    "    for i, palabra in enumerate(palabras_encontradas):\n",
    "        resultado = analizar_similaridad_palabra(X_transpuesta, vectorizer, palabra, df_datos)\n",
    "        if resultado:\n",
    "            resultados.append(resultado)\n",
    "        \n",
    "        if i < len(palabras_encontradas) - 1:  # Separador entre análisis\n",
    "            print(\"\\n\" + \"+\" * 70 + \"\\n\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "palabras_buscar = ['momento', 'respondió', 'preguntó', 'después', 'también']\n",
    "resultados = analisis_completo_similaridad_palabras(X_train, tfidfvect, palabras_buscar, df_datos=df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25ec6938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " análisis de similaridad de : --- ARMADURA ---\n",
      "============================================================\n",
      "Índice en vocabulario: 1758\n",
      "Contexto: Vector de 786 documentos\n",
      "Aparece en 125 documentos:\n",
      "    Documento 336 (lobo_espacial) → valor  TF-IDF: 0.133060\n",
      "    Documento 297 (lobo_espacial) → valor  TF-IDF: 0.129418\n",
      "    Documento 337 (lobo_espacial) → valor  TF-IDF: 0.109153\n",
      "    Documento 172 (lobo_espacial) → valor  TF-IDF: 0.108833\n",
      "    Documento 281 (lobo_espacial) → valor  TF-IDF: 0.103617\n",
      "   ... y 120 documentos más\n",
      "\n",
      "ESTADÍSTICAS DE SIMILARIDAD DE LA PALABRA EN EL ESPACIO DE VECTORES:\n",
      "   Similaridad de la palabra consigo misma: 0.9999999999999997\n",
      "   Similaridad de la palabra promedio: 0.02932272246977407\n",
      "   Similaridad de la palabra máxima (sin incluirse): 0.9999999999999997\n",
      "   Similaridad de la palabra mínima: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analizamos el similaridad de una palabra contra todos los documentos \n",
    "resultado = analizar_similaridad_palabra(X_train.T, tfidfvect, 'armadura', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5acba",
   "metadata": {},
   "source": [
    "A continuación buscamos una palabra específica y muestra en qué documentos aparece con mayor importancia (valor TF-IDF más alto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09663d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabra a buscar: 'respondió'\n",
      "----------------------------------------\n",
      "Top 3 documentos con mayor peso:\n",
      "1. Doc 110 (lobo_espacial) - Peso: 0.0856\n",
      "   Texto: estaba fuera de su lugar. Su cabello rojizo estaba cortado con un estilo que no era habitual en un i...\n",
      "\n",
      "2. Doc 111 (lobo_espacial) - Peso: 0.0832\n",
      "   Texto: de cerca. Sus rasgos eran finos y tenía un aspecto delicado e inteligente, más como el de un eskaldo...\n",
      "\n",
      "3. Doc 633 (neuromante) - Peso: 0.0769\n",
      "   Texto: piscina que caía en las baldosas. —Cath —dijo. —Lupus —respondió él después de una pausa. —¿Qué clas...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# función con Matriz transpuesta, TfidfVectorizer entrenado, palabra y DataFrame\n",
    "def explorar_contexto_palabra(X_transpuesta, vectorizer, palabra, df_datos, top_documentos=3):\n",
    "    \"\"\"\n",
    "    Función auxiliar para explorar en detalle el contexto de una palabra,\n",
    "    qué tipo de textos es más importante esta palabra\n",
    "    \"\"\"\n",
    "    # verificamos si existe la palabra\n",
    "    if palabra not in vectorizer.vocabulary_:\n",
    "        print(f\"Palabra '{palabra}' no encontrada\")\n",
    "        return\n",
    "    # obtenemos información de las palabras\n",
    "    # obtiene la posición de la palabra en el vocabulario\n",
    "    idx_palabra = vectorizer.vocabulary_[palabra]\n",
    "    #  extrae la fila correspondiente a esa palabra de la matriz transpuesta\n",
    "    vector_palabra = X_transpuesta[idx_palabra].toarray().flatten() if hasattr(X_transpuesta, 'toarray') else X_transpuesta[idx_palabra]\n",
    "    \n",
    "    print(f\"\\nPalabra a buscar: '{palabra}'\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Documentos donde aparece con mayor peso\n",
    "    docs_con_valor = []\n",
    "    for doc_idx, valor in enumerate(vector_palabra):\n",
    "        if valor > 0:\n",
    "            etiqueta = df_datos['etiqueta'].iloc[doc_idx]\n",
    "            texto_preview = df_datos['texto'].iloc[doc_idx][:100] + \"...\"\n",
    "            docs_con_valor.append((doc_idx, etiqueta, valor, texto_preview))\n",
    "    \n",
    "    #ordenar por importancia\n",
    "    docs_con_valor = sorted(docs_con_valor, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    #mostramos resultados\n",
    "    print(f\"Top {top_documentos} documentos con mayor peso:\")\n",
    "    for i, (doc_idx, etiqueta, valor, texto) in enumerate(docs_con_valor[:top_documentos], 1):\n",
    "        print(f\"{i}. Doc {doc_idx} ({etiqueta}) - Peso: {valor:.4f}\")\n",
    "        print(f\"   Texto: {texto}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "explorar_contexto_palabra(X_train.T, tfidfvect, 'respondió', df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
